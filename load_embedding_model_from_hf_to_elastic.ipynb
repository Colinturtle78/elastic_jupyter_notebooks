{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " Working with Vectors in Elasticsearch",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNNAuD3/3Zq8XiwA/jHb9ef",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeffvestal/elastic_jupyter_notebooks/blob/main/load_embedding_model_from_hf_to_elastic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading an Sentense Transformer model from Hugging Face into Elastic\n",
        "\n",
        "This code will show you how to set up an ingest pipeline to generate vectors for documents on ingest.\n",
        "\n",
        "Overview of steps\n",
        "1. Set up our python environment\n",
        "2. Setup index mapping\n",
        "3. Configure ingest pipeline\n",
        "4. Index a couple test documents\n",
        "\n",
        "### Requirements\n",
        "This notebook assumes you already have loaded an embedding model into elasticsearch. If you haven't, please start with [this notebook example](https://github.com/jeffvestal/elastic_jupyter_notebooks/blob/main/load_embedding_model_from_hf_to_elastic.ipynb)\n",
        "\n",
        "\n",
        "### Elastic version support\n",
        "Requires Elastic version 8.0+ with a platinum or enterprise license (or trial license)\n",
        "\n",
        "You can set up a [free trial elasticsearch Deployment in Elastic Cloud](https://cloud.elastic.co/registration)."
      ],
      "metadata": {
        "id": "6xoLDtS_6Df1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup\n",
        "This section will set up the python environment with the required libraries"
      ],
      "metadata": {
        "id": "DgxCKQS7mCZw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install and import required python libraries"
      ],
      "metadata": {
        "id": "Ly1f1P-l9ri8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Elastic uses the [eland python library](https://github.com/elastic/eland) to download modesl from Hugging Face hub and load them into elasticsearch"
      ],
      "metadata": {
        "id": "MJAb_8zlPFhQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rUedSzQW9FIF"
      },
      "outputs": [],
      "source": [
        "pip install eland"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install elasticsearch"
      ],
      "metadata": {
        "id": "NK3Wx1I199yB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "id": "cEfiiFXakzdP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install sentence_transformers"
      ],
      "metadata": {
        "id": "I20mDmJboKZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch==1.11"
      ],
      "metadata": {
        "id": "uqcpWrbkBEB9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "from eland.ml.pytorch import PyTorchModel\n",
        "from eland.ml.pytorch.transformers import TransformerModel\n",
        "from elasticsearch import Elasticsearch, helpers\n",
        "from elasticsearch.client import MlClient\n",
        "from pprint import pprint"
      ],
      "metadata": {
        "id": "wyUZXUi4RWWL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configure elasticsearch authentication. \n",
        "The recommended authentication approach is using the [Elastic Cloud ID](https://www.elastic.co/guide/en/cloud/current/ec-cloud-id.html) and a [cluster level API key](https://www.elastic.co/guide/en/kibana/current/api-keys.html)\n",
        "\n",
        "You can use any method you wish to set the required credentials. We are using getpass in this example to prompt for credentials to avoide storing them in github."
      ],
      "metadata": {
        "id": "r7nMIbHke37Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass"
      ],
      "metadata": {
        "id": "Xsd2m7HoTCLm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "es_cloud_id = getpass.getpass('Enter Elastic Cloud ID:  ')\n",
        "es_api_id = getpass.getpass('Enter cluster API key ID:  ') \n",
        "es_api_key = getpass.getpass('Enter cluster API key:  ')"
      ],
      "metadata": {
        "id": "SSGgYHome69o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect to Elastic Cloud"
      ],
      "metadata": {
        "id": "jL4VDnVp96lf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "es = Elasticsearch(cloud_id=es_cloud_id, \n",
        "                   api_key=(es_api_id, es_api_key)\n",
        "                   )\n",
        "es.info() # should return cluster info"
      ],
      "metadata": {
        "id": "I8mVJkKmetXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Information and Status"
      ],
      "metadata": {
        "id": "4UYSzFp3vHdB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## View information about the model\n",
        "This is not required but will allow us to get the model_id as it is stored in elasticsearch as well as verify the model is running / deployed and ready to use in our ingest pipeline"
      ],
      "metadata": {
        "id": "wQwfozwznK4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m = MlClient.get_trained_models(es)\n",
        "m.body"
      ],
      "metadata": {
        "id": "b4Wv8EJvpfZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set the model_id for ease of reference later\n",
        "To make is easy for reference later, we will set  `es_model_id` to the `model_id` listed in the output above"
      ],
      "metadata": {
        "id": "KbbdWiJetJV0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "es_model_id = \"sentence-transformers__msmarco-minilm-l-12-v3\""
      ],
      "metadata": {
        "id": "P8xW5_lCtUE2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *If* the model is not started we will need to deploy the model\n",
        "\n",
        "You will only need to run this if the model hasn't been deployed. \n",
        "\n",
        "This will load the model on the ML nodes and start the process(es) making it available for the NLP task\n",
        "\n",
        "uncomment the code below"
      ],
      "metadata": {
        "id": "oMGw3sk-pbaN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#s = MlClient.start_trained_model_deployment(es, model_id=es_model_id)\n",
        "#s.body"
      ],
      "metadata": {
        "id": "w5muJ1rLqvUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Verify the model started without issue\n",
        "If you aren't sure if the model is started you can check here"
      ],
      "metadata": {
        "id": "ZytlELrsnn_O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stats = MlClient.get_trained_models_stats(es, model_id=es_model_id)\n",
        "stats.body['trained_model_stats'][0]['deployment_stats']['nodes'][0]['routing_state']"
      ],
      "metadata": {
        "id": "ZaQUUWe0Hxwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Elasticsearch index setup\n",
        "Here we will configure an index template with settings and mappings to store our vectors and text data\n",
        "\n",
        "The **important** part here will be setting our vector field to be a `dense_vector` type. This will tell elasticsearch to build the HNSW graph for the vectors so we can then use kNN search later. "
      ],
      "metadata": {
        "id": "KEwsReS8zyOc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the index template\n",
        "We will have the following fields\n",
        "\n",
        "- `vectors` of type `dense_vector`\n",
        "-- it is important to set `dims` to the number of dimensions the model you will use outputs\n",
        "- `title` of type `text`\n",
        "- `summary` of type `text`\n",
        "\n",
        "We will have \n",
        "- 1 primary shard\n",
        "- 0 replica -> *note* in production you will want at least 1 replica\n",
        "\n",
        "This will match new indices with the name matching the pattern of `jupyter-vector-demo*`"
      ],
      "metadata": {
        "id": "KQvNTOJQ2Jk1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index_patterns = \"jupyter-vector-demo*\"\n",
        "settings= {\n",
        "        \"number_of_shards\": 1,\n",
        "        \"number_of_replicas\": 0\n",
        "    }\n",
        "mappings= {\n",
        "        \"properties\": {\n",
        "            \"vectors\": {\n",
        "                \"type\": \"dense_vector\",\n",
        "                \"dims\": 384,\n",
        "                \"index\" : True,\n",
        "                \"similarity\" : \"cosine\"\n",
        "            },\n",
        "            \"title\": {\n",
        "                \"type\": \"text\"\n",
        "            },\n",
        "            \"summary\": {\n",
        "                \"type\": \"text\"\n",
        "            }\n",
        "        }\n",
        "    }"
      ],
      "metadata": {
        "id": "e8079Ic44SEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Apply the template\n",
        "Here we apply the templat and give it a name of `jupyter-vector-demo`. This is just the name of the template if we need to modify it later on."
      ],
      "metadata": {
        "id": "vryddQGB3U6q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "es.indices.put_template(name=\"jupyter-vector-demo-template\", \n",
        "                        index_patterns=index_patterns,\n",
        "                        settings=settings,\n",
        "                        mappings=mappings\n",
        "                        )"
      ],
      "metadata": {
        "id": "LEmOQ4IT3XK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Ingest Pipeline\n",
        "\n",
        "An ingest pipeline has one or more processors and processes documents before they are written into an elasticsearch index. \n",
        "\n",
        "Each processor is designed to perform a various task such as parsing fields or enriching data. \n",
        "\n",
        "The main processor for this pipeline is the `inference` processor. The inference processor sends a specified field to a supervised model and writes the output from the model to a new field along with the original fields in the document. \n",
        "\n",
        "To make it simpler to access the vector, we will copy the vectors to a field named `vectors` and them remove the `ml` field tree which is the default output."
      ],
      "metadata": {
        "id": "3MZ6EBVUTjhN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configure the pipeline"
      ],
      "metadata": {
        "id": "3iOh80S0UhsU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_definition = {\n",
        "    \"description\": \"A pipeline for generating and storing vectors on ingest\",\n",
        "    \"processors\": [\n",
        "      {\n",
        "       \"inference\": {\n",
        "          \"model_id\": \"sentence-transformers__msmarco-minilm-l-12-v3\",\n",
        "          \"field_map\": {\n",
        "           \"summary\": \"text_field\"\n",
        "          }\n",
        "       }\n",
        "     },\n",
        "     {\n",
        "      \"set\": {\n",
        "        \"field\": \"vectors\",\n",
        "        \"copy_from\": \"ml.inference.predicted_value\"\n",
        "        }\n",
        "     },\n",
        "    {\n",
        "      \"remove\": {\n",
        "        \"field\": \"ml\"\n",
        "      }\n",
        "    }\n",
        "  ]\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "id": "DwwyOBWEVd-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the pipeline if it doesn't exist"
      ],
      "metadata": {
        "id": "dHzxqcvIVjyC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if es.ingest.put_pipeline(id=\"jupyter-vector-demo-pipeline\", body=pipeline_definition):\n",
        "    print(\"Pipeline created successfully\")\n",
        "else:\n",
        "    print(\"Failed to create pipeline\")\n"
      ],
      "metadata": {
        "id": "LXZUQI3IVp21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Verify the pipeline\n",
        "Not required but nice to verify everything looks correct"
      ],
      "metadata": {
        "id": "PRyS-1HjcqV7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = es.ingest.get_pipeline(id=\"jupyter-vector-demo-pipeline\")\n",
        "pipeline.body"
      ],
      "metadata": {
        "id": "pH59icc9czcD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "# Ingest Docs and Generate Vectors\n",
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "ruM78vW_hTOy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create sample documents\n",
        "These aren't real blogs just sampls ChatGPT created for me :) "
      ],
      "metadata": {
        "id": "RY3kxbN_hYGC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "samples = [[\"The Power of Word Embeddings in NLP\", \"Word embeddings have revolutionized the field of NLP.\"  ],  \n",
        "    [\"An Introduction to Transformer Models\", \"Transformer models have taken NLP by storm.\"  ],  \n",
        "    [\"Fine-Tuning BERT for Text Classification\", \"Fine-tuning BERT can lead to state-of-the-art results in text classification.\"  ],  \n",
        "    [\"Why GPT-3 is a Game Changer for NLP\", \"GPT-3 has set a new standard for language models in NLP.\"  ],  \n",
        "    [\"Using ELMO for Sentiment Analysis\", \"ELMO can effectively capture contextual information for sentiment analysis.\"  ],  \n",
        "    [\"The Rise of Pre-Trained Models in NLP\", \"Pre-trained models have become increasingly popular in NLP.\"  ]\n",
        "]"
      ],
      "metadata": {
        "id": "MaWpOz6nhr-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the list of docs to ingest"
      ],
      "metadata": {
        "id": "OsbHqadHmif5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "docs = [\n",
        "    {   \"_index\": \"jupyter-vector-demo\",\n",
        "        \"_source\": {\n",
        "           \"title\": sample[0], \n",
        "           \"summary\": sample[1]\n",
        "        }\n",
        "    }\n",
        "    for sample in samples\n",
        "]"
      ],
      "metadata": {
        "id": "-NT3J6FGmcmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Index the docs \n",
        "This will send a bulk index request to elastic, sending all the docs through the ingest pipeline, generating vectors, and storing them in elasticsearch"
      ],
      "metadata": {
        "id": "WmBfO3N6nf37"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "helpers.bulk(es, docs, pipeline=\"jupyter-vector-demo-pipeline\" )"
      ],
      "metadata": {
        "id": "9Jyd_xOyo4xK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Verify one of the docs \n",
        "Let's take a look at one doc and see how it was indexed"
      ],
      "metadata": {
        "id": "-xZ8SyBTpOYh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = es.search(index='jupyter-vector-demo', body={}, size=1)\n",
        "result.body['hits']['hits'][0]['_source']"
      ],
      "metadata": {
        "id": "EasfA-uyqnUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "# knn\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "8M-4Fc-zn7D_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate Vector for Query\n",
        "\n",
        "Before we can run an approximate k-nearest neighbor (kNN) query, we need to convert our query string to a vector."
      ],
      "metadata": {
        "id": "6Hu2n4bmGYkG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set a sample query doc\n",
        "\n",
        "Depending on your specific model, you may need to change the field name from \"text_field\""
      ],
      "metadata": {
        "id": "XXAQXIS0pvfR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "docs =  [\n",
        "    {\n",
        "      \"text_field\": \"State of the art nlp models\"\n",
        "    }\n",
        "  ]"
      ],
      "metadata": {
        "id": "wBNV7q5Dwlz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We call the `_infer` endpoint supplying the model_id and the doc[s] we want to vectorize. "
      ],
      "metadata": {
        "id": "T5_BYcpvrLsb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vec = MlClient.infer_trained_model(es, model_id=es_model_id, docs=docs, )"
      ],
      "metadata": {
        "id": "ZsWg7XPSGbiu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The vector for the first doc can be accessed in the response dict as shown below"
      ],
      "metadata": {
        "id": "CdC3PkTyrZEV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc_0_vector = vec['inference_results'][0]['predicted_value']\n",
        "doc_0_vector"
      ],
      "metadata": {
        "id": "Rle3J5mJXbdf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run the Search\n",
        "\n",
        "We will call the `_search` api and specify the `knn` section. \n",
        "\n",
        "This is a simple example of a search query. Elastic supports combining kNN search with \"traditional\" BM25 search. You can also filter documents to reduce the number of docs that needs to be searched. See the [docs](https://www.elastic.co/guide/en/elasticsearch/reference/current/knn-search-api.html) for more information.\n",
        "\n",
        "This will be a very simple example to get started"
      ],
      "metadata": {
        "id": "pyeoQ8TK8Ddr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create the search paramaters\n",
        "Here we are just specifying the `knn` section, but you can also set all the other search params to pass."
      ],
      "metadata": {
        "id": "31c_Z4eL8mou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "knn = {\n",
        "    \"field\": \"vectors\",\n",
        "    \"query_vector\": doc_0_vector,\n",
        "    \"k\": 2,\n",
        "    \"num_candidates\": 10\n",
        "  }"
      ],
      "metadata": {
        "id": "_xI-NOjv9bbP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Send in the search request"
      ],
      "metadata": {
        "id": "LXFxIpJxQTol"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = es.search(index='jupyter-vector-demo', knn=knn, size=1)\n"
      ],
      "metadata": {
        "id": "bwQoXata8pZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### View the results"
      ],
      "metadata": {
        "id": "wmST0UL1Eqv2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results.body"
      ],
      "metadata": {
        "id": "BAoKozJWEvto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Search Query without returning vectors\n",
        "\n",
        "Often when running kNN search, you don't actually need to return the vectors themselves, you just want to return the fields to display to the end user"
      ],
      "metadata": {
        "id": "Mewh4SoLFBlM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are adding a new paramater `fields` which allows us to specify specific fields to return rather than all of them\n",
        "\n",
        "By setting `source` to False (_source:false) we save having to get the entire source payoad back in the response\n",
        "\n",
        "We are moving the `size` value here simply to gather the paramaters together"
      ],
      "metadata": {
        "id": "qY_xGJ6wQed4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "knn = {\n",
        "    \"field\": \"vectors\",\n",
        "    \"query_vector\": doc_0_vector,\n",
        "    \"k\": 2,\n",
        "    \"num_candidates\": 10\n",
        "  }\n",
        "fields = [\"summary\", \"title\"]\n",
        "size = 1\n",
        "source = False"
      ],
      "metadata": {
        "id": "fgV6DIoCFBlM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = es.search(index='jupyter-vector-demo', \n",
        "                    knn=knn, \n",
        "                    source=source, \n",
        "                    fields=fields, \n",
        "                    size=size\n",
        "                  )\n"
      ],
      "metadata": {
        "id": "Zl9ys10oFBlM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### View the results"
      ],
      "metadata": {
        "id": "sqHp2PMuFBlN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results.body"
      ],
      "metadata": {
        "id": "ZqgB31ZdFBlN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}