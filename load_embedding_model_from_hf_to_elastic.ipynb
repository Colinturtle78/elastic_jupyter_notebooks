{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " Working with Vectors in Elasticsearch",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOV7z5kEgeraLwAQhzb5diC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeffvestal/elastic_jupyter_notebooks/blob/main/load_embedding_model_from_hf_to_elastic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading an Sentense Transformer model from Hugging Face into Elastic\n",
        "\n",
        "This code will show you how to set up an ingest pipeline to generate vectors for documents on ingest.\n",
        "\n",
        "Overview of steps\n",
        "1. Set up our python environment\n",
        "2. Setup index mapping\n",
        "3. Configure ingest pipeline\n",
        "4. Index a couple test documents\n",
        "\n",
        "### Requirements\n",
        "This notebook assumes you already have loaded an embedding model into elasticsearch. If you haven't, please start with [this notebook example](https://github.com/jeffvestal/elastic_jupyter_notebooks/blob/main/load_embedding_model_from_hf_to_elastic.ipynb)\n",
        "\n",
        "\n",
        "### Elastic version support\n",
        "Requires Elastic version 8.0+ with a platinum or enterprise license (or trial license)\n",
        "\n",
        "You can set up a [free trial elasticsearch Deployment in Elastic Cloud](https://cloud.elastic.co/registration)."
      ],
      "metadata": {
        "id": "6xoLDtS_6Df1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup\n",
        "This section will set up the python environment with the required libraries"
      ],
      "metadata": {
        "id": "DgxCKQS7mCZw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install and import required python libraries"
      ],
      "metadata": {
        "id": "Ly1f1P-l9ri8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Elastic uses the [eland python library](https://github.com/elastic/eland) to download modesl from Hugging Face hub and load them into elasticsearch"
      ],
      "metadata": {
        "id": "MJAb_8zlPFhQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rUedSzQW9FIF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8596c9e-1ea0-4e73-9b71-5e3c84a52167"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting eland\n",
            "  Downloading eland-8.3.0-py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.7/143.7 KB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2 in /usr/local/lib/python3.8/dist-packages (from eland) (1.21.6)\n",
            "Requirement already satisfied: pandas<2,>=1.2 in /usr/local/lib/python3.8/dist-packages (from eland) (1.3.5)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.8/dist-packages (from eland) (3.2.2)\n",
            "Collecting elasticsearch<9,>=8.3\n",
            "  Downloading elasticsearch-8.6.1-py3-none-any.whl (385 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.4/385.4 KB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting elastic-transport<9,>=8\n",
            "  Downloading elastic_transport-8.4.0-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 KB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4->eland) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4->eland) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4->eland) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4->eland) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas<2,>=1.2->eland) (2022.7.1)\n",
            "Collecting urllib3<2,>=1.26.2\n",
            "  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from elastic-transport<9,>=8->elasticsearch<9,>=8.3->eland) (2022.12.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib<4->eland) (1.15.0)\n",
            "Installing collected packages: urllib3, elastic-transport, elasticsearch, eland\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed eland-8.3.0 elastic-transport-8.4.0 elasticsearch-8.6.1 urllib3-1.26.14\n"
          ]
        }
      ],
      "source": [
        "pip install eland"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install elasticsearch"
      ],
      "metadata": {
        "id": "NK3Wx1I199yB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6be03102-ec1a-441a-886f-f29260d391a1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: elasticsearch in /usr/local/lib/python3.8/dist-packages (8.6.1)\n",
            "Requirement already satisfied: elastic-transport<9,>=8 in /usr/local/lib/python3.8/dist-packages (from elasticsearch) (8.4.0)\n",
            "Requirement already satisfied: urllib3<2,>=1.26.2 in /usr/local/lib/python3.8/dist-packages (from elastic-transport<9,>=8->elasticsearch) (1.26.14)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from elastic-transport<9,>=8->elasticsearch) (2022.12.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "id": "cEfiiFXakzdP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b38a6c53-3888-43e3-b0dc-8853504f7056"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.26.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.12.0-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.12.0 tokenizers-0.13.2 transformers-4.26.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install sentence_transformers"
      ],
      "metadata": {
        "id": "I20mDmJboKZw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a1dc121-fa2c-4f8f-ec14-e78d16400a02"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentence_transformers\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 KB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.8/dist-packages (from sentence_transformers) (4.26.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from sentence_transformers) (4.64.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from sentence_transformers) (1.13.1+cu116)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (from sentence_transformers) (0.14.1+cu116)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from sentence_transformers) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from sentence_transformers) (1.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from sentence_transformers) (1.7.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (from sentence_transformers) (3.7)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from sentence_transformers) (0.12.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.9.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.25.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2022.6.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.13.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk->sentence_transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk->sentence_transformers) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->sentence_transformers) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision->sentence_transformers) (7.1.2)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.10)\n",
            "Building wheels for collected packages: sentence_transformers\n",
            "  Building wheel for sentence_transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence_transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125938 sha256=3dd71edc95b5e5c3cebba9fac90c7fa7f18e909ac740311c75bb6922ed64381a\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/6f/8c/d88aec621f3f542d26fac0342bef5e693335d125f4e54aeffe\n",
            "Successfully built sentence_transformers\n",
            "Installing collected packages: sentencepiece, sentence_transformers\n",
            "Successfully installed sentence_transformers-2.2.2 sentencepiece-0.1.97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch==1.11"
      ],
      "metadata": {
        "id": "uqcpWrbkBEB9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8edf4bd4-1774-4769-9622-4a9d58286c68"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch==1.11\n",
            "  Downloading torch-1.11.0-cp38-cp38-manylinux1_x86_64.whl (750.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m750.6/750.6 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.11) (4.4.0)\n",
            "Installing collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.13.1+cu116\n",
            "    Uninstalling torch-1.13.1+cu116:\n",
            "      Successfully uninstalled torch-1.13.1+cu116\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.14.1+cu116 requires torch==1.13.1, but you have torch 1.11.0 which is incompatible.\n",
            "torchtext 0.14.1 requires torch==1.13.1, but you have torch 1.11.0 which is incompatible.\n",
            "torchaudio 0.13.1+cu116 requires torch==1.13.1, but you have torch 1.11.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-1.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "from eland.ml.pytorch import PyTorchModel\n",
        "from eland.ml.pytorch.transformers import TransformerModel\n",
        "from elasticsearch import Elasticsearch, helpers\n",
        "from elasticsearch.client import MlClient\n",
        "from pprint import pprint"
      ],
      "metadata": {
        "id": "wyUZXUi4RWWL"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configure elasticsearch authentication. \n",
        "The recommended authentication approach is using the [Elastic Cloud ID](https://www.elastic.co/guide/en/cloud/current/ec-cloud-id.html) and a [cluster level API key](https://www.elastic.co/guide/en/kibana/current/api-keys.html)\n",
        "\n",
        "You can use any method you wish to set the required credentials. We are using getpass in this example to prompt for credentials to avoide storing them in github."
      ],
      "metadata": {
        "id": "r7nMIbHke37Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass"
      ],
      "metadata": {
        "id": "Xsd2m7HoTCLm"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "es_cloud_id = getpass.getpass('Enter Elastic Cloud ID:  ')\n",
        "es_api_id = getpass.getpass('Enter cluster API key ID:  ') \n",
        "es_api_key = getpass.getpass('Enter cluster API key:  ')"
      ],
      "metadata": {
        "id": "SSGgYHome69o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0bce557-a27f-42ca-b481-9beec1c183b7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter Elastic Cloud ID:  ··········\n",
            "Enter cluster API key ID:  ··········\n",
            "Enter cluster API key:  ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect to Elastic Cloud"
      ],
      "metadata": {
        "id": "jL4VDnVp96lf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "es = Elasticsearch(cloud_id=es_cloud_id, \n",
        "                   api_key=(es_api_id, es_api_key)\n",
        "                   )\n",
        "es.info() # should return cluster info"
      ],
      "metadata": {
        "id": "I8mVJkKmetXo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f09e003a-8138-488f-c1bd-8d92f5f1463c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ObjectApiResponse({'name': 'instance-0000000001', 'cluster_name': 'a7bf48bf42ad403ab45dd6b90b860f85', 'cluster_uuid': 'gEbjuhUOSyCVzG4Gz2SQ2w', 'version': {'number': '8.6.0', 'build_flavor': 'default', 'build_type': 'docker', 'build_hash': 'f67ef2df40237445caa70e2fef79471cc608d70d', 'build_date': '2023-01-04T09:35:21.782467981Z', 'build_snapshot': False, 'lucene_version': '9.4.2', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Information and Status"
      ],
      "metadata": {
        "id": "4UYSzFp3vHdB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## View information about the model\n",
        "This is not required but will allow us to get the model_id as it is stored in elasticsearch as well as verify the model is running / deployed and ready to use in our ingest pipeline"
      ],
      "metadata": {
        "id": "wQwfozwznK4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m = MlClient.get_trained_models(es)\n",
        "m.body"
      ],
      "metadata": {
        "id": "b4Wv8EJvpfZI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddca28d5-4464-4917-ebe6-d7ace7e73014"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'count': 17,\n",
              " 'trained_model_configs': [{'model_id': 'bert-base-uncased',\n",
              "   'model_type': 'pytorch',\n",
              "   'created_by': 'api_user',\n",
              "   'version': '8.1.0',\n",
              "   'create_time': 1649359786787,\n",
              "   'model_size_bytes': 0,\n",
              "   'estimated_operations': 0,\n",
              "   'license_level': 'platinum',\n",
              "   'description': \"Model bert-base-uncased for task type 'fill_mask'\",\n",
              "   'tags': [],\n",
              "   'input': {'field_names': ['text_field']},\n",
              "   'inference_config': {'fill_mask': {'vocabulary': {'index': '.ml-inference-native-000001'},\n",
              "     'tokenization': {'bert': {'do_lower_case': True,\n",
              "       'with_special_tokens': True,\n",
              "       'max_sequence_length': 512,\n",
              "       'truncate': 'first',\n",
              "       'span': -1}},\n",
              "     'num_top_classes': 0}},\n",
              "   'location': {'index': {'name': '.ml-inference-native-000001'}}},\n",
              "  {'model_id': 'bhadresh-savani__distilbert-base-uncased-emotion',\n",
              "   'model_type': 'pytorch',\n",
              "   'created_by': 'api_user',\n",
              "   'version': '8.1.0',\n",
              "   'create_time': 1649342073282,\n",
              "   'model_size_bytes': 0,\n",
              "   'estimated_operations': 0,\n",
              "   'license_level': 'platinum',\n",
              "   'description': \"Model bhadresh-savani/distilbert-base-uncased-emotion for task type 'text_classification'\",\n",
              "   'tags': [],\n",
              "   'input': {'field_names': ['text_field']},\n",
              "   'inference_config': {'text_classification': {'vocabulary': {'index': '.ml-inference-native-000001'},\n",
              "     'tokenization': {'bert': {'do_lower_case': True,\n",
              "       'with_special_tokens': True,\n",
              "       'max_sequence_length': 512,\n",
              "       'truncate': 'first',\n",
              "       'span': -1}},\n",
              "     'classification_labels': ['sadness',\n",
              "      'joy',\n",
              "      'love',\n",
              "      'anger',\n",
              "      'fear',\n",
              "      'surprise'],\n",
              "     'num_top_classes': 0}},\n",
              "   'location': {'index': {'name': '.ml-inference-native-000001'}}},\n",
              "  {'model_id': 'customer-churn-demo-1651021875022',\n",
              "   'model_type': 'tree_ensemble',\n",
              "   'created_by': '_xpack',\n",
              "   'version': '8.1.3',\n",
              "   'create_time': 1651021875022,\n",
              "   'model_size_bytes': 20648,\n",
              "   'estimated_operations': 43,\n",
              "   'license_level': 'platinum',\n",
              "   'description': '',\n",
              "   'tags': ['customer-churn-demo'],\n",
              "   'metadata': {'analytics_config': {'max_num_threads': 1,\n",
              "     'create_time': 1651021864744,\n",
              "     'model_memory_limit': '23mb',\n",
              "     'allow_lazy_start': False,\n",
              "     'description': '',\n",
              "     'analyzed_fields': {'excludes': [],\n",
              "      'includes': ['account_length',\n",
              "       'call_charges',\n",
              "       'call_count',\n",
              "       'call_duration',\n",
              "       'churn',\n",
              "       'customer_service_calls',\n",
              "       'international_plan',\n",
              "       'number_vmail_messages',\n",
              "       'phone_number',\n",
              "       'state',\n",
              "       'voice_mail_plan']},\n",
              "     'id': 'customer-churn-demo',\n",
              "     'source': {'query': {'match_all': {}}, 'index': ['churn-transform']},\n",
              "     'dest': {'index': 'customer-churn-demo', 'results_field': 'ml'},\n",
              "     'analysis': {'classification': {'early_stopping_enabled': True,\n",
              "       'randomize_seed': -4050415395007543941,\n",
              "       'dependent_variable': 'churn',\n",
              "       'num_top_classes': -1,\n",
              "       'training_percent': 80.0,\n",
              "       'class_assignment_objective': 'maximize_minimum_recall',\n",
              "       'num_top_feature_importance_values': 5,\n",
              "       'prediction_field_name': 'churn_prediction'}},\n",
              "     'version': '8.1.3'}},\n",
              "   'input': {'field_names': ['account_length',\n",
              "     'call_charges',\n",
              "     'call_count',\n",
              "     'call_duration',\n",
              "     'customer_service_calls',\n",
              "     'international_plan',\n",
              "     'number_vmail_messages',\n",
              "     'phone_number',\n",
              "     'state',\n",
              "     'voice_mail_plan']},\n",
              "   'inference_config': {'classification': {'num_top_classes': -1,\n",
              "     'top_classes_results_field': 'top_classes',\n",
              "     'results_field': 'churn_prediction',\n",
              "     'num_top_feature_importance_values': 5,\n",
              "     'prediction_field_type': 'number'}}},\n",
              "  {'model_id': 'deepset__electra-base-squad2',\n",
              "   'model_type': 'pytorch',\n",
              "   'created_by': 'api_user',\n",
              "   'version': '8.3.2',\n",
              "   'create_time': 1660073309585,\n",
              "   'model_size_bytes': 0,\n",
              "   'estimated_operations': 0,\n",
              "   'license_level': 'platinum',\n",
              "   'description': \"Model typeform/distilbert-base-uncased-mnli for task type 'zero_shot_classification'\",\n",
              "   'tags': [],\n",
              "   'input': {'field_names': ['text_field']},\n",
              "   'inference_config': {'zero_shot_classification': {'vocabulary': {'index': '.ml-inference-native-000001'},\n",
              "     'tokenization': {'bert': {'do_lower_case': True,\n",
              "       'with_special_tokens': True,\n",
              "       'max_sequence_length': 512,\n",
              "       'truncate': 'first',\n",
              "       'span': -1}},\n",
              "     'classification_labels': ['ENTAILMENT', 'NEUTRAL', 'CONTRADICTION'],\n",
              "     'multi_label': False,\n",
              "     'hypothesis_template': 'This example is {}.'}},\n",
              "   'location': {'index': {'name': '.ml-inference-native-000001'}}},\n",
              "  {'model_id': 'distilbert-base-cased-distilled-squad',\n",
              "   'model_type': 'pytorch',\n",
              "   'created_by': 'api_user',\n",
              "   'version': '8.3.2',\n",
              "   'create_time': 1660073530064,\n",
              "   'model_size_bytes': 0,\n",
              "   'estimated_operations': 0,\n",
              "   'license_level': 'platinum',\n",
              "   'description': \"Model distilbert-base-cased-distilled-squad for task type 'question_answering'\",\n",
              "   'tags': [],\n",
              "   'input': {'field_names': ['text_field']},\n",
              "   'inference_config': {'question_answering': {'num_top_classes': 0,\n",
              "     'max_answer_length': 15,\n",
              "     'vocabulary': {'index': '.ml-inference-native-000001'},\n",
              "     'tokenization': {'bert': {'do_lower_case': False,\n",
              "       'with_special_tokens': True,\n",
              "       'max_sequence_length': 386,\n",
              "       'truncate': 'none',\n",
              "       'span': 128}}}},\n",
              "   'location': {'index': {'name': '.ml-inference-native-000001'}}},\n",
              "  {'model_id': 'distilbert-base-uncased-finetuned-sst-2-english',\n",
              "   'model_type': 'pytorch',\n",
              "   'created_by': 'api_user',\n",
              "   'version': '8.1.0',\n",
              "   'create_time': 1649342009993,\n",
              "   'model_size_bytes': 0,\n",
              "   'estimated_operations': 0,\n",
              "   'license_level': 'platinum',\n",
              "   'description': \"Model distilbert-base-uncased-finetuned-sst-2-english for task type 'text_classification'\",\n",
              "   'tags': [],\n",
              "   'input': {'field_names': ['text_field']},\n",
              "   'inference_config': {'text_classification': {'vocabulary': {'index': '.ml-inference-native-000001'},\n",
              "     'tokenization': {'bert': {'do_lower_case': True,\n",
              "       'with_special_tokens': True,\n",
              "       'max_sequence_length': 512,\n",
              "       'truncate': 'first',\n",
              "       'span': -1}},\n",
              "     'classification_labels': ['NEGATIVE', 'POSITIVE'],\n",
              "     'num_top_classes': 0}},\n",
              "   'location': {'index': {'name': '.ml-inference-native-000001'}}},\n",
              "  {'model_id': 'dslim__bert-base-ner',\n",
              "   'model_type': 'pytorch',\n",
              "   'created_by': 'api_user',\n",
              "   'version': '8.1.0',\n",
              "   'create_time': 1649342315478,\n",
              "   'model_size_bytes': 0,\n",
              "   'estimated_operations': 0,\n",
              "   'license_level': 'platinum',\n",
              "   'description': \"Model dslim/bert-base-NER for task type 'ner'\",\n",
              "   'tags': [],\n",
              "   'input': {'field_names': ['text_field']},\n",
              "   'inference_config': {'ner': {'vocabulary': {'index': '.ml-inference-native-000001'},\n",
              "     'tokenization': {'bert': {'do_lower_case': False,\n",
              "       'with_special_tokens': True,\n",
              "       'max_sequence_length': 512,\n",
              "       'truncate': 'first',\n",
              "       'span': -1}},\n",
              "     'classification_labels': ['O',\n",
              "      'B_MISC',\n",
              "      'I_MISC',\n",
              "      'B_PER',\n",
              "      'I_PER',\n",
              "      'B_ORG',\n",
              "      'I_ORG',\n",
              "      'B_LOC',\n",
              "      'I_LOC']}},\n",
              "   'location': {'index': {'name': '.ml-inference-native-000001'}}},\n",
              "  {'model_id': 'elastic__distilbert-base-cased-finetuned-conll03-english',\n",
              "   'model_type': 'pytorch',\n",
              "   'created_by': 'api_user',\n",
              "   'version': '8.1.0',\n",
              "   'create_time': 1649342480962,\n",
              "   'model_size_bytes': 0,\n",
              "   'estimated_operations': 0,\n",
              "   'license_level': 'platinum',\n",
              "   'description': \"Model elastic/distilbert-base-cased-finetuned-conll03-english for task type 'ner'\",\n",
              "   'tags': [],\n",
              "   'input': {'field_names': ['text_field']},\n",
              "   'inference_config': {'ner': {'vocabulary': {'index': '.ml-inference-native-000001'},\n",
              "     'tokenization': {'bert': {'do_lower_case': False,\n",
              "       'with_special_tokens': True,\n",
              "       'max_sequence_length': 512,\n",
              "       'truncate': 'first',\n",
              "       'span': -1}},\n",
              "     'classification_labels': ['O',\n",
              "      'B_PER',\n",
              "      'I_PER',\n",
              "      'B_ORG',\n",
              "      'I_ORG',\n",
              "      'B_LOC',\n",
              "      'I_LOC',\n",
              "      'B_MISC',\n",
              "      'I_MISC']}},\n",
              "   'location': {'index': {'name': '.ml-inference-native-000001'}}},\n",
              "  {'model_id': 'elastic__distilbert-base-uncased-finetuned-conll03-english',\n",
              "   'model_type': 'pytorch',\n",
              "   'created_by': 'api_user',\n",
              "   'version': '8.1.0',\n",
              "   'create_time': 1649342422141,\n",
              "   'model_size_bytes': 0,\n",
              "   'estimated_operations': 0,\n",
              "   'license_level': 'platinum',\n",
              "   'description': \"Model elastic/distilbert-base-uncased-finetuned-conll03-english for task type 'ner'\",\n",
              "   'tags': [],\n",
              "   'input': {'field_names': ['text_field']},\n",
              "   'inference_config': {'ner': {'vocabulary': {'index': '.ml-inference-native-000001'},\n",
              "     'tokenization': {'bert': {'do_lower_case': True,\n",
              "       'with_special_tokens': True,\n",
              "       'max_sequence_length': 512,\n",
              "       'truncate': 'first',\n",
              "       'span': -1}},\n",
              "     'classification_labels': ['O',\n",
              "      'B_PER',\n",
              "      'I_PER',\n",
              "      'B_ORG',\n",
              "      'I_ORG',\n",
              "      'B_LOC',\n",
              "      'I_LOC',\n",
              "      'B_MISC',\n",
              "      'I_MISC']}},\n",
              "   'location': {'index': {'name': '.ml-inference-native-000001'}}},\n",
              "  {'model_id': 'lang_ident_model_1',\n",
              "   'model_type': 'lang_ident',\n",
              "   'created_by': '_xpack',\n",
              "   'version': '7.6.0',\n",
              "   'create_time': 1575548914594,\n",
              "   'model_size_bytes': 1053992,\n",
              "   'estimated_operations': 39629,\n",
              "   'license_level': 'basic',\n",
              "   'description': 'Model used for identifying language from arbitrary input text.',\n",
              "   'tags': ['lang_ident', 'prepackaged'],\n",
              "   'input': {'field_names': ['text']},\n",
              "   'inference_config': {'classification': {'num_top_classes': 0,\n",
              "     'top_classes_results_field': 'top_classes',\n",
              "     'results_field': 'predicted_value',\n",
              "     'num_top_feature_importance_values': 0,\n",
              "     'prediction_field_type': 'string'}}},\n",
              "  {'model_id': 'nateraw__bert-base-uncased-emotion',\n",
              "   'model_type': 'pytorch',\n",
              "   'created_by': 'api_user',\n",
              "   'version': '8.1.0',\n",
              "   'create_time': 1649342174945,\n",
              "   'model_size_bytes': 0,\n",
              "   'estimated_operations': 0,\n",
              "   'license_level': 'platinum',\n",
              "   'description': \"Model nateraw/bert-base-uncased-emotion for task type 'text_classification'\",\n",
              "   'tags': [],\n",
              "   'input': {'field_names': ['text_field']},\n",
              "   'inference_config': {'text_classification': {'vocabulary': {'index': '.ml-inference-native-000001'},\n",
              "     'tokenization': {'bert': {'do_lower_case': True,\n",
              "       'with_special_tokens': True,\n",
              "       'max_sequence_length': 512,\n",
              "       'truncate': 'first',\n",
              "       'span': -1}},\n",
              "     'classification_labels': ['sadness',\n",
              "      'joy',\n",
              "      'love',\n",
              "      'anger',\n",
              "      'fear',\n",
              "      'surprise'],\n",
              "     'num_top_classes': 0}},\n",
              "   'location': {'index': {'name': '.ml-inference-native-000001'}}},\n",
              "  {'model_id': 'sentence-transformers__all-mpnet-base-v2',\n",
              "   'model_type': 'pytorch',\n",
              "   'created_by': 'api_user',\n",
              "   'version': '8.6.0',\n",
              "   'create_time': 1674094974194,\n",
              "   'model_size_bytes': 0,\n",
              "   'estimated_operations': 0,\n",
              "   'license_level': 'platinum',\n",
              "   'description': \"Model sentence-transformers/all-mpnet-base-v2 for task type 'text_embedding'\",\n",
              "   'tags': [],\n",
              "   'input': {'field_names': ['text_field']},\n",
              "   'inference_config': {'text_embedding': {'vocabulary': {'index': '.ml-inference-native-000001'},\n",
              "     'tokenization': {'mpnet': {'do_lower_case': True,\n",
              "       'with_special_tokens': True,\n",
              "       'max_sequence_length': 512,\n",
              "       'truncate': 'first',\n",
              "       'span': -1}}}},\n",
              "   'location': {'index': {'name': '.ml-inference-native-000001'}}},\n",
              "  {'model_id': 'sentence-transformers__clip-vit-b-32-multilingual-v1',\n",
              "   'model_type': 'pytorch',\n",
              "   'created_by': 'api_user',\n",
              "   'version': '8.1.0',\n",
              "   'create_time': 1649359551583,\n",
              "   'model_size_bytes': 0,\n",
              "   'estimated_operations': 0,\n",
              "   'license_level': 'platinum',\n",
              "   'description': \"Model sentence-transformers/clip-ViT-B-32-multilingual-v1 for task type 'text_embedding'\",\n",
              "   'tags': [],\n",
              "   'input': {'field_names': ['text_field']},\n",
              "   'inference_config': {'text_embedding': {'vocabulary': {'index': '.ml-inference-native-000001'},\n",
              "     'tokenization': {'bert': {'do_lower_case': False,\n",
              "       'with_special_tokens': True,\n",
              "       'max_sequence_length': 512,\n",
              "       'truncate': 'first',\n",
              "       'span': -1}}}},\n",
              "   'location': {'index': {'name': '.ml-inference-native-000001'}}},\n",
              "  {'model_id': 'sentence-transformers__msmarco-minilm-l-12-v3',\n",
              "   'model_type': 'pytorch',\n",
              "   'created_by': 'api_user',\n",
              "   'version': '8.6.0',\n",
              "   'create_time': 1675731184156,\n",
              "   'model_size_bytes': 0,\n",
              "   'estimated_operations': 0,\n",
              "   'license_level': 'platinum',\n",
              "   'description': \"Model sentence-transformers/msmarco-MiniLM-L-12-v3 for task type 'text_embedding'\",\n",
              "   'tags': [],\n",
              "   'input': {'field_names': ['text_field']},\n",
              "   'inference_config': {'text_embedding': {'vocabulary': {'index': '.ml-inference-native-000001'},\n",
              "     'tokenization': {'bert': {'do_lower_case': True,\n",
              "       'with_special_tokens': True,\n",
              "       'max_sequence_length': 512,\n",
              "       'truncate': 'first',\n",
              "       'span': -1}}}},\n",
              "   'location': {'index': {'name': '.ml-inference-native-000001'}}},\n",
              "  {'model_id': 'sentence-transformers__multi-qa-mpnet-base-cos-v1',\n",
              "   'model_type': 'pytorch',\n",
              "   'created_by': 'api_user',\n",
              "   'version': '8.4.0',\n",
              "   'create_time': 1663593758641,\n",
              "   'model_size_bytes': 0,\n",
              "   'estimated_operations': 0,\n",
              "   'license_level': 'platinum',\n",
              "   'description': \"Model sentence-transformers/multi-qa-mpnet-base-cos-v1 for task type 'text_embedding'\",\n",
              "   'tags': [],\n",
              "   'input': {'field_names': ['text_field']},\n",
              "   'inference_config': {'text_embedding': {'vocabulary': {'index': '.ml-inference-native-000001'},\n",
              "     'tokenization': {'mpnet': {'do_lower_case': True,\n",
              "       'with_special_tokens': True,\n",
              "       'max_sequence_length': 512,\n",
              "       'truncate': 'first',\n",
              "       'span': -1}}}},\n",
              "   'location': {'index': {'name': '.ml-inference-native-000001'}}},\n",
              "  {'model_id': 'typeform__distilbert-base-uncased-mnli',\n",
              "   'model_type': 'pytorch',\n",
              "   'created_by': 'api_user',\n",
              "   'version': '8.2.3',\n",
              "   'create_time': 1656293734093,\n",
              "   'model_size_bytes': 0,\n",
              "   'estimated_operations': 0,\n",
              "   'license_level': 'platinum',\n",
              "   'description': \"Model typeform/distilbert-base-uncased-mnli for task type 'zero_shot_classification'\",\n",
              "   'tags': [],\n",
              "   'input': {'field_names': ['text_field']},\n",
              "   'inference_config': {'zero_shot_classification': {'vocabulary': {'index': '.ml-inference-native-000001'},\n",
              "     'tokenization': {'bert': {'do_lower_case': True,\n",
              "       'with_special_tokens': True,\n",
              "       'max_sequence_length': 512,\n",
              "       'truncate': 'first',\n",
              "       'span': -1}},\n",
              "     'classification_labels': ['ENTAILMENT', 'NEUTRAL', 'CONTRADICTION'],\n",
              "     'multi_label': False,\n",
              "     'hypothesis_template': 'This example is {}.'}},\n",
              "   'location': {'index': {'name': '.ml-inference-native-000001'}}},\n",
              "  {'model_id': 'zzz-churn-1651078075650',\n",
              "   'model_type': 'tree_ensemble',\n",
              "   'created_by': '_xpack',\n",
              "   'version': '8.1.3',\n",
              "   'create_time': 1651078075650,\n",
              "   'model_size_bytes': 75552,\n",
              "   'estimated_operations': 284,\n",
              "   'license_level': 'platinum',\n",
              "   'description': '',\n",
              "   'tags': ['zzz-churn'],\n",
              "   'metadata': {'analytics_config': {'max_num_threads': 1,\n",
              "     'create_time': 1651078061149,\n",
              "     'model_memory_limit': '23mb',\n",
              "     'allow_lazy_start': False,\n",
              "     'description': '',\n",
              "     'analyzed_fields': {'excludes': [],\n",
              "      'includes': ['account_length',\n",
              "       'call_charges',\n",
              "       'call_count',\n",
              "       'call_duration',\n",
              "       'churn',\n",
              "       'customer_service_calls',\n",
              "       'international_plan',\n",
              "       'number_vmail_messages',\n",
              "       'phone_number',\n",
              "       'state',\n",
              "       'voice_mail_plan']},\n",
              "     'id': 'zzz-churn',\n",
              "     'source': {'query': {'match_all': {}}, 'index': ['churn-transform']},\n",
              "     'dest': {'index': 'zzz-churn', 'results_field': 'ml'},\n",
              "     'analysis': {'classification': {'early_stopping_enabled': True,\n",
              "       'randomize_seed': 942836294817143535,\n",
              "       'dependent_variable': 'churn',\n",
              "       'num_top_classes': -1,\n",
              "       'training_percent': 80.0,\n",
              "       'class_assignment_objective': 'maximize_minimum_recall',\n",
              "       'num_top_feature_importance_values': 5,\n",
              "       'prediction_field_name': 'churn_prediction'}},\n",
              "     'version': '8.1.3'}},\n",
              "   'input': {'field_names': ['account_length',\n",
              "     'call_charges',\n",
              "     'call_count',\n",
              "     'call_duration',\n",
              "     'customer_service_calls',\n",
              "     'international_plan',\n",
              "     'number_vmail_messages',\n",
              "     'phone_number',\n",
              "     'state',\n",
              "     'voice_mail_plan']},\n",
              "   'inference_config': {'classification': {'num_top_classes': -1,\n",
              "     'top_classes_results_field': 'top_classes',\n",
              "     'results_field': 'churn_prediction',\n",
              "     'num_top_feature_importance_values': 5,\n",
              "     'prediction_field_type': 'number'}}}]}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set the model_id for ease of reference later\n",
        "To make is easy for reference later, we will set  `es_model_id` to the `model_id` listed in the output above"
      ],
      "metadata": {
        "id": "KbbdWiJetJV0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "es_model_id = \"sentence-transformers__msmarco-minilm-l-12-v3\""
      ],
      "metadata": {
        "id": "P8xW5_lCtUE2"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *If* the model is not started we will need to deploy the model\n",
        "\n",
        "You will only need to run this if the model hasn't been deployed. \n",
        "\n",
        "This will load the model on the ML nodes and start the process(es) making it available for the NLP task\n",
        "\n",
        "uncomment the code below"
      ],
      "metadata": {
        "id": "oMGw3sk-pbaN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#s = MlClient.start_trained_model_deployment(es, model_id=es_model_id)\n",
        "#s.body"
      ],
      "metadata": {
        "id": "w5muJ1rLqvUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Verify the model started without issue\n",
        "If you aren't sure if the model is started you can check here"
      ],
      "metadata": {
        "id": "ZytlELrsnn_O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stats = MlClient.get_trained_models_stats(es, model_id=es_model_id)\n",
        "stats.body['trained_model_stats'][0]['deployment_stats']['nodes'][0]['routing_state']"
      ],
      "metadata": {
        "id": "ZaQUUWe0Hxwz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6832a864-5985-42d2-c26f-39f4f3191de5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'routing_state': 'started'}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Elasticsearch index setup\n",
        "Here we will configure an index template with settings and mappings to store our vectors and text data\n",
        "\n",
        "The **important** part here will be setting our vector field to be a `dense_vector` type. This will tell elasticsearch to build the HNSW graph for the vectors so we can then use kNN search later. "
      ],
      "metadata": {
        "id": "KEwsReS8zyOc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the index template\n",
        "We will have the following fields\n",
        "\n",
        "- `vectors` of type `dense_vector`\n",
        "-- it is important to set `dims` to the number of dimensions the model you will use outputs\n",
        "- `title` of type `text`\n",
        "- `summary` of type `text`\n",
        "\n",
        "We will have \n",
        "- 1 primary shard\n",
        "- 0 replica -> *note* in production you will want at least 1 replica\n",
        "\n",
        "This will match new indices with the name matching the pattern of `jupyter-vector-demo*`"
      ],
      "metadata": {
        "id": "KQvNTOJQ2Jk1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index_patterns = \"jupyter-vector-demo*\"\n",
        "settings= {\n",
        "        \"number_of_shards\": 1,\n",
        "        \"number_of_replicas\": 0\n",
        "    }\n",
        "mappings= {\n",
        "        \"properties\": {\n",
        "            \"vectors\": {\n",
        "                \"type\": \"dense_vector\",\n",
        "                \"dims\": 384,\n",
        "                \"index\" : True,\n",
        "                \"similarity\" : \"cosine\"\n",
        "            },\n",
        "            \"title\": {\n",
        "                \"type\": \"text\"\n",
        "            },\n",
        "            \"summary\": {\n",
        "                \"type\": \"text\"\n",
        "            }\n",
        "        }\n",
        "    }"
      ],
      "metadata": {
        "id": "e8079Ic44SEO"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Apply the template\n",
        "Here we apply the templat and give it a name of `jupyter-vector-demo`. This is just the name of the template if we need to modify it later on."
      ],
      "metadata": {
        "id": "vryddQGB3U6q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "es.indices.put_template(name=\"jupyter-vector-demo-template\", \n",
        "                        index_patterns=index_patterns,\n",
        "                        settings=settings,\n",
        "                        mappings=mappings\n",
        "                        )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEmOQ4IT3XK8",
        "outputId": "3bce1921-34a6-426d-ccc0-e4a6eed99fda"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-49-2da7a83c4045>:1: ElasticsearchWarning: Legacy index templates are deprecated in favor of composable templates.\n",
            "  es.indices.put_template(name=\"jupyter-vector-demo-template\",\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ObjectApiResponse({'acknowledged': True})"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Ingest Pipeline\n",
        "\n",
        "An ingest pipeline has one or more processors and processes documents before they are written into an elasticsearch index. \n",
        "\n",
        "Each processor is designed to perform a various task such as parsing fields or enriching data. \n",
        "\n",
        "The main processor for this pipeline is the `inference` processor. The inference processor sends a specified field to a supervised model and writes the output from the model to a new field along with the original fields in the document. \n",
        "\n",
        "To make it simpler to access the vector, we will copy the vectors to a field named `vectors` and them remove the `ml` field tree which is the default output."
      ],
      "metadata": {
        "id": "3MZ6EBVUTjhN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configure the pipeline"
      ],
      "metadata": {
        "id": "3iOh80S0UhsU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_definition = {\n",
        "    \"description\": \"A pipeline for generating and storing vectors on ingest\",\n",
        "    \"processors\": [\n",
        "      {\n",
        "       \"inference\": {\n",
        "          \"model_id\": \"sentence-transformers__msmarco-minilm-l-12-v3\",\n",
        "          \"field_map\": {\n",
        "           \"summary\": \"text_field\"\n",
        "          }\n",
        "       }\n",
        "     },\n",
        "     {\n",
        "      \"set\": {\n",
        "        \"field\": \"vectors\",\n",
        "        \"copy_from\": \"ml.inference.predicted_value\"\n",
        "        }\n",
        "     },\n",
        "    {\n",
        "      \"remove\": {\n",
        "        \"field\": \"ml\"\n",
        "      }\n",
        "    }\n",
        "  ]\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "id": "DwwyOBWEVd-P"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the pipeline if it doesn't exist"
      ],
      "metadata": {
        "id": "dHzxqcvIVjyC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if es.ingest.put_pipeline(id=\"jupyter-vector-demo-pipeline\", body=pipeline_definition):\n",
        "    print(\"Pipeline created successfully\")\n",
        "else:\n",
        "    print(\"Failed to create pipeline\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXZUQI3IVp21",
        "outputId": "d0e6ac63-1f8a-4105-e473-d3a7c84f7cc1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-6be263036b07>:1: DeprecationWarning: The 'body' parameter is deprecated and will be removed in a future version. Instead use individual parameters.\n",
            "  if es.ingest.put_pipeline(id=\"jupyter-vector-demo-pipeline\", body=pipeline_definition):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pipeline created successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Verify the pipeline\n",
        "Not required but nice to verify everything looks correct"
      ],
      "metadata": {
        "id": "PRyS-1HjcqV7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = es.ingest.get_pipeline(id=\"jupyter-vector-demo-pipeline\")\n",
        "pipeline.body"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pH59icc9czcD",
        "outputId": "7c5882f9-3e77-4377-8188-4702c2555d0d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'jupyter-vector-demo-pipeline': {'description': 'A pipeline for generating and storing vectors on ingest',\n",
              "  'processors': [{'inference': {'model_id': 'sentence-transformers__msmarco-minilm-l-12-v3',\n",
              "     'field_map': {'summary': 'text_field'}}},\n",
              "   {'set': {'field': 'vectors', 'copy_from': 'ml.inference.predicted_value'}},\n",
              "   {'remove': {'field': 'ml'}}]}}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "# Ingest Docs and Generate Vectors\n",
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "ruM78vW_hTOy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create sample documents\n",
        "These aren't real blogs just sampls ChatGPT created for me :) "
      ],
      "metadata": {
        "id": "RY3kxbN_hYGC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "samples = [[\"The Power of Word Embeddings in NLP\", \"Word embeddings have revolutionized the field of NLP.\"  ],  \n",
        "    [\"An Introduction to Transformer Models\", \"Transformer models have taken NLP by storm.\"  ],  \n",
        "    [\"Fine-Tuning BERT for Text Classification\", \"Fine-tuning BERT can lead to state-of-the-art results in text classification.\"  ],  \n",
        "    [\"Why GPT-3 is a Game Changer for NLP\", \"GPT-3 has set a new standard for language models in NLP.\"  ],  \n",
        "    [\"Using ELMO for Sentiment Analysis\", \"ELMO can effectively capture contextual information for sentiment analysis.\"  ],  \n",
        "    [\"The Rise of Pre-Trained Models in NLP\", \"Pre-trained models have become increasingly popular in NLP.\"  ]\n",
        "]"
      ],
      "metadata": {
        "id": "MaWpOz6nhr-L"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the list of docs to ingest"
      ],
      "metadata": {
        "id": "OsbHqadHmif5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "docs = [\n",
        "    {   \"_index\": \"jupyter-vector-demo\",\n",
        "        \"_source\": {\n",
        "           \"title\": sample[0], \n",
        "           \"summary\": sample[1]\n",
        "        }\n",
        "    }\n",
        "    for sample in samples\n",
        "]"
      ],
      "metadata": {
        "id": "-NT3J6FGmcmR"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Index the docs \n",
        "This will send a bulk index request to elastic, sending all the docs through the ingest pipeline, generating vectors, and storing them in elasticsearch"
      ],
      "metadata": {
        "id": "WmBfO3N6nf37"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "helpers.bulk(es, docs, pipeline=\"jupyter-vector-demo-pipeline\", create_if_missing=True)"
      ],
      "metadata": {
        "id": "9Jyd_xOyo4xK",
        "outputId": "14cc259e-f9b2-4021-aabc-29de7d92c872",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        }
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-90928bcb1088>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhelpers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbulk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"jupyter-vector-demo-pipeline\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_if_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/elasticsearch/helpers/actions.py\u001b[0m in \u001b[0;36mbulk\u001b[0;34m(client, actions, stats_only, ignore_status, *args, **kwargs)\u001b[0m\n\u001b[1;32m    522\u001b[0m     \u001b[0;31m# make streaming_bulk yield successful results so we can count them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"yield_ok\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 524\u001b[0;31m     for ok, item in streaming_bulk(\n\u001b[0m\u001b[1;32m    525\u001b[0m         \u001b[0mclient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_status\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_status\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m     ):\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/elasticsearch/helpers/actions.py\u001b[0m in \u001b[0;36mstreaming_bulk\u001b[0;34m(client, actions, chunk_size, max_chunk_bytes, raise_on_error, expand_action_callback, raise_on_exception, max_retries, initial_backoff, max_backoff, yield_ok, ignore_status, *args, **kwargs)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m                 for data, (ok, info) in zip(\n\u001b[0m\u001b[1;32m    439\u001b[0m                     \u001b[0mbulk_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m                     _process_bulk_chunk(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/elasticsearch/helpers/actions.py\u001b[0m in \u001b[0;36m_process_bulk_chunk\u001b[0;34m(client, bulk_actions, bulk_data, raise_on_exception, raise_on_error, ignore_status, *args, **kwargs)\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;31m# send the actual request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbulk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbulk_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mApiError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         gen = _process_bulk_chunk_error(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/elasticsearch/_sync/client/utils.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    412\u001b[0m                         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m  \u001b[0;31m# type: ignore[return-value]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: bulk() got an unexpected keyword argument 'create_if_missing'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Verify one of the docs \n",
        "Let's take a look at one doc and see how it was indexed"
      ],
      "metadata": {
        "id": "-xZ8SyBTpOYh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = es.search(index='jupyter-vector-demo', body={}, size=1)\n",
        "result.body['hits']['hits'][0]['_source']"
      ],
      "metadata": {
        "id": "EasfA-uyqnUu",
        "outputId": "7d7c5005-15b2-4825-a26a-d66e5a9a9e6f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'summary': 'Word embeddings have revolutionized the field of NLP.',\n",
              " 'vectors': [0.010032681748270988,\n",
              "  0.1762128621339798,\n",
              "  0.025519631803035736,\n",
              "  -0.1699194610118866,\n",
              "  -0.023978114128112793,\n",
              "  -0.17380699515342712,\n",
              "  -0.16619500517845154,\n",
              "  -0.4496205449104309,\n",
              "  0.14203619956970215,\n",
              "  -0.025377998128533363,\n",
              "  -0.21256506443023682,\n",
              "  0.3052826225757599,\n",
              "  -0.048612333834171295,\n",
              "  -0.25566211342811584,\n",
              "  0.0038711531087756157,\n",
              "  0.2568204402923584,\n",
              "  -0.4086630940437317,\n",
              "  0.3276959955692291,\n",
              "  0.18598729372024536,\n",
              "  -0.08290590345859528,\n",
              "  -0.06666664034128189,\n",
              "  0.33053335547447205,\n",
              "  0.33372732996940613,\n",
              "  -0.1446480005979538,\n",
              "  0.4143035411834717,\n",
              "  -0.11616694182157516,\n",
              "  -0.003925261087715626,\n",
              "  -0.002277584746479988,\n",
              "  0.11438579857349396,\n",
              "  -0.5439679026603699,\n",
              "  0.27566054463386536,\n",
              "  -0.0374893993139267,\n",
              "  -0.08002748340368271,\n",
              "  0.010440019890666008,\n",
              "  -0.1600598394870758,\n",
              "  0.3334594666957855,\n",
              "  -0.10152608156204224,\n",
              "  0.02321258932352066,\n",
              "  0.20382066071033478,\n",
              "  -0.1916440725326538,\n",
              "  -0.1388297826051712,\n",
              "  0.37902501225471497,\n",
              "  -0.04430069401860237,\n",
              "  0.32136645913124084,\n",
              "  -0.16018790006637573,\n",
              "  0.19779500365257263,\n",
              "  -0.2832280695438385,\n",
              "  0.0859389454126358,\n",
              "  -0.473023921251297,\n",
              "  0.09796655178070068,\n",
              "  0.20842307806015015,\n",
              "  -0.267062246799469,\n",
              "  -0.37661731243133545,\n",
              "  -0.05230841413140297,\n",
              "  -0.06716089695692062,\n",
              "  -0.13890135288238525,\n",
              "  -0.16205139458179474,\n",
              "  0.08126524835824966,\n",
              "  0.28704774379730225,\n",
              "  -0.011510878801345825,\n",
              "  -0.32544440031051636,\n",
              "  -0.1466817408800125,\n",
              "  -0.003871465567499399,\n",
              "  0.30373308062553406,\n",
              "  -0.20426684617996216,\n",
              "  -0.2936669588088989,\n",
              "  0.3036183714866638,\n",
              "  0.14096753299236298,\n",
              "  0.0915607139468193,\n",
              "  -0.15724872052669525,\n",
              "  0.3138686418533325,\n",
              "  0.04831458628177643,\n",
              "  -0.16329094767570496,\n",
              "  -0.007745109498500824,\n",
              "  0.1793602705001831,\n",
              "  0.24291455745697021,\n",
              "  -0.22218793630599976,\n",
              "  0.08741872757673264,\n",
              "  0.19035081565380096,\n",
              "  -0.43611717224121094,\n",
              "  0.30468565225601196,\n",
              "  -0.1680964082479477,\n",
              "  0.1548786461353302,\n",
              "  0.12694509327411652,\n",
              "  -0.1276470273733139,\n",
              "  0.4511055648326874,\n",
              "  -0.06106796860694885,\n",
              "  -0.11483831703662872,\n",
              "  -0.07130511850118637,\n",
              "  0.04382399469614029,\n",
              "  -0.37933066487312317,\n",
              "  0.06097496300935745,\n",
              "  0.22323444485664368,\n",
              "  0.2402425855398178,\n",
              "  0.16654038429260254,\n",
              "  0.3757209777832031,\n",
              "  -0.061677735298871994,\n",
              "  -0.015006838366389275,\n",
              "  -0.12497437000274658,\n",
              "  -0.15345343947410583,\n",
              "  -0.661713182926178,\n",
              "  0.1515805572271347,\n",
              "  0.29897454380989075,\n",
              "  -0.05012664198875427,\n",
              "  0.24251669645309448,\n",
              "  -0.39051371812820435,\n",
              "  0.1954205483198166,\n",
              "  0.04592065513134003,\n",
              "  0.04279063642024994,\n",
              "  -0.13283438980579376,\n",
              "  -0.01773732714354992,\n",
              "  0.06610727310180664,\n",
              "  -0.033261965960264206,\n",
              "  0.06924843043088913,\n",
              "  -0.13319692015647888,\n",
              "  0.011596601456403732,\n",
              "  -0.052977703511714935,\n",
              "  0.30448317527770996,\n",
              "  -0.11892402917146683,\n",
              "  0.3835408687591553,\n",
              "  0.00497152004390955,\n",
              "  0.11301559954881668,\n",
              "  -0.2317688763141632,\n",
              "  0.08484381437301636,\n",
              "  -0.10650791972875595,\n",
              "  -0.2112412452697754,\n",
              "  0.144095778465271,\n",
              "  0.02216828055679798,\n",
              "  0.2651268541812897,\n",
              "  0.03701300919055939,\n",
              "  0.03915839269757271,\n",
              "  0.20060232281684875,\n",
              "  0.22062444686889648,\n",
              "  0.1384294331073761,\n",
              "  0.026845155283808708,\n",
              "  -0.3362780809402466,\n",
              "  0.30015942454338074,\n",
              "  -0.003684830153360963,\n",
              "  0.10962706059217453,\n",
              "  0.008101986721158028,\n",
              "  -0.1687563955783844,\n",
              "  0.7016637921333313,\n",
              "  0.04183086007833481,\n",
              "  0.037665992975234985,\n",
              "  -0.18789415061473846,\n",
              "  0.7686008214950562,\n",
              "  0.08697739988565445,\n",
              "  0.3333893120288849,\n",
              "  0.09039875864982605,\n",
              "  0.24200092256069183,\n",
              "  -0.07217226177453995,\n",
              "  -0.1744546741247177,\n",
              "  -0.270945280790329,\n",
              "  -0.10717982053756714,\n",
              "  0.03839978575706482,\n",
              "  -0.368570476770401,\n",
              "  -0.13853102922439575,\n",
              "  0.001488659530878067,\n",
              "  -0.4927905201911926,\n",
              "  -0.5222116708755493,\n",
              "  -0.27629339694976807,\n",
              "  0.030765026807785034,\n",
              "  0.31607621908187866,\n",
              "  -0.07783487439155579,\n",
              "  0.09397298097610474,\n",
              "  -0.21535523235797882,\n",
              "  0.12934830784797668,\n",
              "  -0.24826893210411072,\n",
              "  -0.18926864862442017,\n",
              "  -0.1281132847070694,\n",
              "  -0.02872392162680626,\n",
              "  -0.38948383927345276,\n",
              "  -0.0339779332280159,\n",
              "  0.28240102529525757,\n",
              "  0.11251436173915863,\n",
              "  -0.0662350282073021,\n",
              "  0.1454838663339615,\n",
              "  0.11583597958087921,\n",
              "  0.1646285355091095,\n",
              "  0.08677040040493011,\n",
              "  0.19270917773246765,\n",
              "  0.07735946774482727,\n",
              "  0.3860474228858948,\n",
              "  -0.3712460994720459,\n",
              "  -0.1286894977092743,\n",
              "  -0.11245828121900558,\n",
              "  0.32034122943878174,\n",
              "  -0.09479968994855881,\n",
              "  0.05449985712766647,\n",
              "  0.4644034504890442,\n",
              "  0.263383686542511,\n",
              "  0.41495633125305176,\n",
              "  0.17197206616401672,\n",
              "  0.02462974190711975,\n",
              "  -0.018856626003980637,\n",
              "  0.2026979625225067,\n",
              "  0.16714894771575928,\n",
              "  0.09703963249921799,\n",
              "  -0.3404725193977356,\n",
              "  -0.15150274336338043,\n",
              "  -0.40223726630210876,\n",
              "  -0.5346086025238037,\n",
              "  -0.30734187364578247,\n",
              "  -4.8376619815826416e-05,\n",
              "  0.12784168124198914,\n",
              "  0.06205667927861214,\n",
              "  0.07503609359264374,\n",
              "  0.16256849467754364,\n",
              "  -0.16973991692066193,\n",
              "  -0.41604527831077576,\n",
              "  -0.12505362927913666,\n",
              "  0.04618328809738159,\n",
              "  0.004021893255412579,\n",
              "  -0.2923681437969208,\n",
              "  -0.16745318472385406,\n",
              "  0.1658027470111847,\n",
              "  -0.13665609061717987,\n",
              "  0.12381550669670105,\n",
              "  0.19877426326274872,\n",
              "  0.25898200273513794,\n",
              "  0.009330308064818382,\n",
              "  -0.12910795211791992,\n",
              "  -0.18305523693561554,\n",
              "  -0.35239970684051514,\n",
              "  -0.4441892206668854,\n",
              "  0.14482155442237854,\n",
              "  -0.18826735019683838,\n",
              "  0.1972256451845169,\n",
              "  -0.04410776123404503,\n",
              "  0.24189789593219757,\n",
              "  -0.27055540680885315,\n",
              "  0.001469687558710575,\n",
              "  0.1394444704055786,\n",
              "  -0.11129102855920792,\n",
              "  -0.3858795762062073,\n",
              "  0.47282907366752625,\n",
              "  -0.14133629202842712,\n",
              "  0.23695360124111176,\n",
              "  -0.24302639067173004,\n",
              "  -0.16741690039634705,\n",
              "  -0.07818872481584549,\n",
              "  0.460094690322876,\n",
              "  -0.12092813104391098,\n",
              "  0.33683982491493225,\n",
              "  0.22358588874340057,\n",
              "  -0.1790560483932495,\n",
              "  -0.2695803940296173,\n",
              "  -0.04322345182299614,\n",
              "  0.4446008801460266,\n",
              "  -0.23253904283046722,\n",
              "  0.3760213553905487,\n",
              "  -0.15049321949481964,\n",
              "  0.1141674593091011,\n",
              "  -0.24966569244861603,\n",
              "  0.16753284633159637,\n",
              "  0.14530032873153687,\n",
              "  -0.6228993535041809,\n",
              "  0.48703980445861816,\n",
              "  -0.01104468759149313,\n",
              "  -0.09769867360591888,\n",
              "  0.10057110339403152,\n",
              "  0.4144342243671417,\n",
              "  -0.0647408738732338,\n",
              "  0.22508682310581207,\n",
              "  0.44749099016189575,\n",
              "  -0.03953789547085762,\n",
              "  -0.24547064304351807,\n",
              "  0.03448929265141487,\n",
              "  -0.2941175401210785,\n",
              "  0.516021192073822,\n",
              "  -0.3144625425338745,\n",
              "  -0.06151212006807327,\n",
              "  0.5407902598381042,\n",
              "  0.4146342873573303,\n",
              "  0.11005298793315887,\n",
              "  0.21248780190944672,\n",
              "  -0.3503025770187378,\n",
              "  -0.38159260153770447,\n",
              "  0.14698167145252228,\n",
              "  -0.8056509494781494,\n",
              "  0.2305271178483963,\n",
              "  -0.28230786323547363,\n",
              "  0.2974928319454193,\n",
              "  0.07520581036806107,\n",
              "  -0.5518996715545654,\n",
              "  0.005541225895285606,\n",
              "  0.316977858543396,\n",
              "  -0.10387808829545975,\n",
              "  -0.14633971452713013,\n",
              "  0.05676618963479996,\n",
              "  0.020114215090870857,\n",
              "  0.04281662032008171,\n",
              "  -0.3360200822353363,\n",
              "  -0.05903079733252525,\n",
              "  -0.12661276757717133,\n",
              "  0.04908997192978859,\n",
              "  0.11221811175346375,\n",
              "  -0.23372092843055725,\n",
              "  -0.07346522063016891,\n",
              "  0.044868335127830505,\n",
              "  0.36033421754837036,\n",
              "  -0.10546552389860153,\n",
              "  -0.396112859249115,\n",
              "  -0.01586468145251274,\n",
              "  0.1946466714143753,\n",
              "  -0.07061821222305298,\n",
              "  0.050276510417461395,\n",
              "  -0.036979641765356064,\n",
              "  0.20366300642490387,\n",
              "  -0.08705127239227295,\n",
              "  -0.2600180208683014,\n",
              "  -0.03638719022274017,\n",
              "  0.006905806250870228,\n",
              "  0.1024557575583458,\n",
              "  0.14157100021839142,\n",
              "  0.13277865946292877,\n",
              "  -0.09790337085723877,\n",
              "  0.16558043658733368,\n",
              "  -0.20628471672534943,\n",
              "  -0.3025404214859009,\n",
              "  -0.13834622502326965,\n",
              "  0.17916184663772583,\n",
              "  0.08811825513839722,\n",
              "  -0.22862015664577484,\n",
              "  0.2925940752029419,\n",
              "  0.2568452060222626,\n",
              "  -0.43952256441116333,\n",
              "  0.34763842821121216,\n",
              "  -0.17448848485946655,\n",
              "  0.018143221735954285,\n",
              "  0.5731684565544128,\n",
              "  0.08708477765321732,\n",
              "  -0.010868699289858341,\n",
              "  0.056181490421295166,\n",
              "  0.005232223775237799,\n",
              "  -0.4109986126422882,\n",
              "  0.22696036100387573,\n",
              "  -0.4349289536476135,\n",
              "  -0.2005762755870819,\n",
              "  -0.005611589644104242,\n",
              "  -0.015551194548606873,\n",
              "  0.1995200663805008,\n",
              "  -0.145658478140831,\n",
              "  -0.4562265872955322,\n",
              "  -0.22845612466335297,\n",
              "  0.38211050629615784,\n",
              "  0.2523682713508606,\n",
              "  -0.21734148263931274,\n",
              "  -0.053443100303411484,\n",
              "  -0.4149189293384552,\n",
              "  0.2734101116657257,\n",
              "  0.13286033272743225,\n",
              "  -0.2441968023777008,\n",
              "  0.28856879472732544,\n",
              "  -0.48364466428756714,\n",
              "  0.16929635405540466,\n",
              "  -0.20000550150871277,\n",
              "  0.5764199495315552,\n",
              "  -0.07278209924697876,\n",
              "  0.21699264645576477,\n",
              "  -0.5692649483680725,\n",
              "  0.15299884974956512,\n",
              "  0.007581155747175217,\n",
              "  -0.15162332355976105,\n",
              "  0.10485149174928665,\n",
              "  0.11903543025255203,\n",
              "  0.3342404365539551,\n",
              "  -0.08898359537124634,\n",
              "  0.11060051620006561,\n",
              "  0.15170933306217194,\n",
              "  0.0731426477432251,\n",
              "  0.05095366761088371,\n",
              "  0.14728380739688873,\n",
              "  0.1350313276052475,\n",
              "  0.02669757790863514,\n",
              "  0.2353757619857788,\n",
              "  -0.3949529230594635,\n",
              "  -0.03813446685671806,\n",
              "  -0.5668659806251526,\n",
              "  -0.026847869157791138,\n",
              "  -0.2043425291776657,\n",
              "  0.05703246593475342,\n",
              "  0.08149492740631104,\n",
              "  -0.09619612246751785],\n",
              " 'title': 'The Power of Word Embeddings in NLP'}"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "# knn\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "8M-4Fc-zn7D_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate Vector for Query\n",
        "\n",
        "Before we can run an approximate k-nearest neighbor (kNN) query, we need to convert our query string to a vector."
      ],
      "metadata": {
        "id": "6Hu2n4bmGYkG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set a sample query doc\n",
        "\n",
        "Depending on your specific model, you may need to change the field name from \"text_field\""
      ],
      "metadata": {
        "id": "XXAQXIS0pvfR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "docs =  [\n",
        "    {\n",
        "      \"text_field\": \"State of the art nlp models\"\n",
        "    }\n",
        "  ]"
      ],
      "metadata": {
        "id": "wBNV7q5Dwlz6"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We call the `_infer` endpoint supplying the model_id and the doc[s] we want to vectorize. "
      ],
      "metadata": {
        "id": "T5_BYcpvrLsb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vec = MlClient.infer_trained_model(es, model_id=es_model_id, docs=docs, )"
      ],
      "metadata": {
        "id": "ZsWg7XPSGbiu"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The vector for the first doc can be accessed in the response dict as shown below"
      ],
      "metadata": {
        "id": "CdC3PkTyrZEV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc_0_vector = vec['inference_results'][0]['predicted_value']\n",
        "doc_0_vector"
      ],
      "metadata": {
        "id": "Rle3J5mJXbdf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72420104-75e2-40df-de6b-2dd6025c0402"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-0.05313778668642044,\n",
              " 0.2675938904285431,\n",
              " -0.1571311205625534,\n",
              " -0.16366317868232727,\n",
              " 0.1534436196088791,\n",
              " 0.4014796018600464,\n",
              " 0.09830273687839508,\n",
              " -0.4107570946216583,\n",
              " 0.6688247919082642,\n",
              " 0.18063218891620636,\n",
              " 0.23392875492572784,\n",
              " 0.25056707859039307,\n",
              " 0.1332893967628479,\n",
              " -0.027977390214800835,\n",
              " 0.19046132266521454,\n",
              " 0.11570954322814941,\n",
              " -0.24199819564819336,\n",
              " -0.1414170265197754,\n",
              " 0.5337180495262146,\n",
              " 0.5993724465370178,\n",
              " 0.30228930711746216,\n",
              " 0.09154966473579407,\n",
              " 0.17977407574653625,\n",
              " 0.14795929193496704,\n",
              " 0.3506891429424286,\n",
              " -0.18918591737747192,\n",
              " 0.41521453857421875,\n",
              " 0.2111051082611084,\n",
              " 0.038915835320949554,\n",
              " -0.09822694212198257,\n",
              " -0.1743984818458557,\n",
              " -0.24724091589450836,\n",
              " -0.35224899649620056,\n",
              " 0.28879034519195557,\n",
              " 0.3031083047389984,\n",
              " 0.24868538975715637,\n",
              " -0.41746076941490173,\n",
              " 0.009341837838292122,\n",
              " 0.36109238862991333,\n",
              " -0.07405922561883926,\n",
              " 0.33332574367523193,\n",
              " 0.212000772356987,\n",
              " 0.04666478931903839,\n",
              " 0.0004928873386234045,\n",
              " 0.15392138063907623,\n",
              " 0.17112930119037628,\n",
              " -0.15815283358097076,\n",
              " 0.12857863306999207,\n",
              " -0.42602431774139404,\n",
              " -0.38502565026283264,\n",
              " -0.02870614267885685,\n",
              " -0.6302883625030518,\n",
              " -0.11315255612134933,\n",
              " -0.13658316433429718,\n",
              " -0.03965291380882263,\n",
              " -0.15094029903411865,\n",
              " 0.10674044489860535,\n",
              " -0.25545141100883484,\n",
              " -0.05476846545934677,\n",
              " -0.04362183436751366,\n",
              " 0.38044294714927673,\n",
              " -0.4732389450073242,\n",
              " -0.379167377948761,\n",
              " -0.15133318305015564,\n",
              " -0.025977225974202156,\n",
              " -0.0677255243062973,\n",
              " 0.48051008582115173,\n",
              " 0.11748412996530533,\n",
              " 0.022637708112597466,\n",
              " -0.3476393222808838,\n",
              " 0.2965397536754608,\n",
              " -0.2893139123916626,\n",
              " 0.24659961462020874,\n",
              " -0.46311289072036743,\n",
              " -0.14702394604682922,\n",
              " 0.006846811156719923,\n",
              " 0.20043939352035522,\n",
              " -0.228693425655365,\n",
              " 0.27364251017570496,\n",
              " -0.34589171409606934,\n",
              " 0.40584683418273926,\n",
              " -0.06906290352344513,\n",
              " 0.2837143540382385,\n",
              " 0.26346081495285034,\n",
              " 0.09736768901348114,\n",
              " 0.03107854723930359,\n",
              " 0.10758822411298752,\n",
              " 0.13224776089191437,\n",
              " 0.3241303563117981,\n",
              " -0.2325678914785385,\n",
              " -0.5237423181533813,\n",
              " 0.18121790885925293,\n",
              " 0.07940370589494705,\n",
              " 0.34615007042884827,\n",
              " 0.4305537939071655,\n",
              " 0.35905420780181885,\n",
              " 0.17768368124961853,\n",
              " 0.3896424174308777,\n",
              " 0.06822380423545837,\n",
              " 0.7025945782661438,\n",
              " -0.6108377575874329,\n",
              " 0.07147175073623657,\n",
              " 0.39164912700653076,\n",
              " -0.1359146386384964,\n",
              " -0.35706543922424316,\n",
              " 0.011011036112904549,\n",
              " -0.0009589741821400821,\n",
              " -0.1194368451833725,\n",
              " -0.24842678010463715,\n",
              " -0.2464340776205063,\n",
              " -0.383693665266037,\n",
              " 0.20082610845565796,\n",
              " -0.2160356491804123,\n",
              " 0.3904187083244324,\n",
              " 0.033663276582956314,\n",
              " -0.3158789277076721,\n",
              " -0.2655874788761139,\n",
              " 0.4207614064216614,\n",
              " 0.18855983018875122,\n",
              " -0.172987699508667,\n",
              " 0.06913931667804718,\n",
              " -0.3600057065486908,\n",
              " 0.07413700222969055,\n",
              " 0.13469290733337402,\n",
              " 0.09027200937271118,\n",
              " -0.11934121698141098,\n",
              " -0.11070792376995087,\n",
              " -0.36597180366516113,\n",
              " 0.05561907961964607,\n",
              " 0.27120697498321533,\n",
              " -0.004331860225647688,\n",
              " 0.10055277496576309,\n",
              " 0.10211651027202606,\n",
              " 0.14864924550056458,\n",
              " 0.40243908762931824,\n",
              " -0.21440018713474274,\n",
              " -0.19257715344429016,\n",
              " 0.3857206106185913,\n",
              " 0.22464317083358765,\n",
              " 0.5283658504486084,\n",
              " -0.010344360023736954,\n",
              " 0.4781934916973114,\n",
              " 0.06669559329748154,\n",
              " 0.2886180281639099,\n",
              " 0.10078142583370209,\n",
              " 0.3882623612880707,\n",
              " 0.07766212522983551,\n",
              " 0.20268839597702026,\n",
              " 0.0966576337814331,\n",
              " 0.3418177366256714,\n",
              " -0.19797581434249878,\n",
              " -0.38436055183410645,\n",
              " 0.0036932197399437428,\n",
              " -0.08136314153671265,\n",
              " -0.03476814925670624,\n",
              " -0.41992175579071045,\n",
              " -0.47579097747802734,\n",
              " 0.2512659430503845,\n",
              " -0.10707825422286987,\n",
              " 0.10770373791456223,\n",
              " -0.3494507074356079,\n",
              " -0.1604742407798767,\n",
              " 0.015237491577863693,\n",
              " -0.15604808926582336,\n",
              " -0.20926456153392792,\n",
              " -0.12104245275259018,\n",
              " -0.05076933652162552,\n",
              " -0.25409117341041565,\n",
              " -0.27991247177124023,\n",
              " 0.17730186879634857,\n",
              " -0.09758305549621582,\n",
              " -0.31704503297805786,\n",
              " -0.1274828165769577,\n",
              " 0.15433357656002045,\n",
              " 0.08510405570268631,\n",
              " 0.22649304568767548,\n",
              " -0.04166587442159653,\n",
              " 0.16791921854019165,\n",
              " -0.16090624034404755,\n",
              " 0.08040542155504227,\n",
              " -0.3682500422000885,\n",
              " -0.12798717617988586,\n",
              " 0.35840415954589844,\n",
              " -0.2574348449707031,\n",
              " -0.026338381692767143,\n",
              " 0.01868591271340847,\n",
              " 0.32503199577331543,\n",
              " -0.4485665559768677,\n",
              " -0.05286400765180588,\n",
              " 0.22282426059246063,\n",
              " 0.43794548511505127,\n",
              " 0.29900062084198,\n",
              " 0.009284044615924358,\n",
              " 0.23684147000312805,\n",
              " -0.5429515838623047,\n",
              " -0.31786468625068665,\n",
              " 0.45664018392562866,\n",
              " 0.060796406120061874,\n",
              " -0.10404780507087708,\n",
              " -0.023283690214157104,\n",
              " 0.034467265009880066,\n",
              " -0.0612930990755558,\n",
              " -0.21129325032234192,\n",
              " -0.05666646733880043,\n",
              " 0.03392947092652321,\n",
              " 0.27531394362449646,\n",
              " 0.08556973934173584,\n",
              " 0.003906437195837498,\n",
              " -0.8041192889213562,\n",
              " 0.29203781485557556,\n",
              " -0.14081424474716187,\n",
              " 0.08465170860290527,\n",
              " 0.23112599551677704,\n",
              " -0.17683884501457214,\n",
              " -0.0029309364035725594,\n",
              " 0.02711128257215023,\n",
              " -0.018343668431043625,\n",
              " -0.21561656892299652,\n",
              " -0.17109161615371704,\n",
              " 0.0385073646903038,\n",
              " -0.03322873264551163,\n",
              " -0.21153360605239868,\n",
              " -0.09702383726835251,\n",
              " -0.24762879312038422,\n",
              " -0.13780087232589722,\n",
              " -0.10412909090518951,\n",
              " -0.023038702085614204,\n",
              " -0.4990309178829193,\n",
              " 0.395301878452301,\n",
              " -0.4377683103084564,\n",
              " 0.1947833150625229,\n",
              " 0.06618179380893707,\n",
              " 0.1844850778579712,\n",
              " 0.174588143825531,\n",
              " 0.33170121908187866,\n",
              " 0.23188893496990204,\n",
              " -0.2563478946685791,\n",
              " 0.20697784423828125,\n",
              " -0.06823407113552094,\n",
              " -0.23520003259181976,\n",
              " 0.06656083464622498,\n",
              " -0.08034518361091614,\n",
              " 0.08250711113214493,\n",
              " 0.08761283755302429,\n",
              " 0.29531988501548767,\n",
              " -0.2024572342634201,\n",
              " -0.04982399195432663,\n",
              " 0.07042619585990906,\n",
              " 0.028886828571558,\n",
              " 0.05764937400817871,\n",
              " 0.07541416585445404,\n",
              " -0.411749929189682,\n",
              " 0.025506122037768364,\n",
              " 0.027371449396014214,\n",
              " 0.044042572379112244,\n",
              " -0.4153223931789398,\n",
              " -0.23098152875900269,\n",
              " 0.7948786616325378,\n",
              " -0.5289158821105957,\n",
              " 0.012471293099224567,\n",
              " 0.21778307855129242,\n",
              " -0.0681445449590683,\n",
              " -0.5627495050430298,\n",
              " 0.4413609206676483,\n",
              " 0.5928148031234741,\n",
              " -0.164845272898674,\n",
              " 0.03585411235690117,\n",
              " 0.12464973330497742,\n",
              " -0.3463047742843628,\n",
              " -0.22903987765312195,\n",
              " 0.2715308964252472,\n",
              " -0.3602283298969269,\n",
              " 0.1986674964427948,\n",
              " 0.03881606459617615,\n",
              " 0.051585812121629715,\n",
              " 0.16841572523117065,\n",
              " 0.06374417245388031,\n",
              " -0.33575284481048584,\n",
              " 0.039998989552259445,\n",
              " -0.5977403521537781,\n",
              " -0.1050502136349678,\n",
              " 0.019129008054733276,\n",
              " -0.05330701917409897,\n",
              " 0.286224365234375,\n",
              " -0.08753177523612976,\n",
              " -0.14986903965473175,\n",
              " -0.021136697381734848,\n",
              " -0.09172705560922623,\n",
              " -0.48016807436943054,\n",
              " -0.23436181247234344,\n",
              " -0.6668360233306885,\n",
              " -0.09570945799350739,\n",
              " 0.3540618121623993,\n",
              " -0.031226400285959244,\n",
              " -0.30458465218544006,\n",
              " -0.08876920491456985,\n",
              " 0.018741561099886894,\n",
              " 0.15157347917556763,\n",
              " 0.08905021101236343,\n",
              " 0.12935873866081238,\n",
              " 0.2889595329761505,\n",
              " -0.18846052885055542,\n",
              " 0.14176605641841888,\n",
              " -0.35938113927841187,\n",
              " 0.053535155951976776,\n",
              " -0.33667680621147156,\n",
              " -0.5296044945716858,\n",
              " 0.2004680037498474,\n",
              " 0.5011056065559387,\n",
              " 0.1719793677330017,\n",
              " -0.28694021701812744,\n",
              " -0.13849550485610962,\n",
              " 0.2340002804994583,\n",
              " -0.1346394121646881,\n",
              " 0.23914888501167297,\n",
              " 0.02513045445084572,\n",
              " 0.17280593514442444,\n",
              " -0.05826664716005325,\n",
              " 0.14986863732337952,\n",
              " -0.5507075190544128,\n",
              " -0.18260227143764496,\n",
              " 0.47605085372924805,\n",
              " 0.7765026688575745,\n",
              " -0.2029687762260437,\n",
              " 0.16896632313728333,\n",
              " -0.19451028108596802,\n",
              " -0.1322987973690033,\n",
              " -0.2500968277454376,\n",
              " -0.06467162072658539,\n",
              " 0.047667983919382095,\n",
              " 0.39399269223213196,\n",
              " -0.025586843490600586,\n",
              " 0.2545696496963501,\n",
              " -0.10309978574514389,\n",
              " -0.264693021774292,\n",
              " -0.4398646354675293,\n",
              " 0.31384384632110596,\n",
              " 0.2137007862329483,\n",
              " -0.022847745567560196,\n",
              " -0.06964652985334396,\n",
              " 0.2731466293334961,\n",
              " 0.264546275138855,\n",
              " 0.05587691813707352,\n",
              " -0.16544747352600098,\n",
              " -0.379942387342453,\n",
              " 0.40363526344299316,\n",
              " 0.0292039904743433,\n",
              " -0.6814029216766357,\n",
              " -0.24587705731391907,\n",
              " -0.058862634003162384,\n",
              " 0.04849990829825401,\n",
              " 0.42957359552383423,\n",
              " 0.0024093075189739466,\n",
              " 0.33694902062416077,\n",
              " -0.2157869189977646,\n",
              " 0.04495423287153244,\n",
              " -0.30256029963493347,\n",
              " 0.4941636323928833,\n",
              " 0.10591539740562439,\n",
              " -0.09013484418392181,\n",
              " -0.3236739933490753,\n",
              " -0.05899643152952194,\n",
              " -0.027136722579598427,\n",
              " -0.30554521083831787,\n",
              " 0.31558263301849365,\n",
              " 0.038139086216688156,\n",
              " 0.4866322875022888,\n",
              " -0.3968709409236908,\n",
              " -0.04814010486006737,\n",
              " 0.07382158190011978,\n",
              " -0.19407854974269867,\n",
              " -0.2460525780916214,\n",
              " -0.19306430220603943,\n",
              " 0.07289163768291473,\n",
              " -0.17045117914676666,\n",
              " 0.1510584056377411,\n",
              " -0.022922150790691376,\n",
              " 0.2184385061264038,\n",
              " -0.41927945613861084,\n",
              " 0.030954526737332344,\n",
              " -0.17558541893959045,\n",
              " -0.33807098865509033,\n",
              " -0.03246273100376129,\n",
              " -0.4050305485725403]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run the Search\n",
        "\n",
        "We will call the `_search` api and specify the `knn` section. \n",
        "\n",
        "This is a simple example of a search query. Elastic supports combining kNN search with \"traditional\" BM25 search. You can also filter documents to reduce the number of docs that needs to be searched. See the [docs](https://www.elastic.co/guide/en/elasticsearch/reference/current/knn-search-api.html) for more information.\n",
        "\n",
        "This will be a very simple example to get started"
      ],
      "metadata": {
        "id": "pyeoQ8TK8Ddr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create the search body"
      ],
      "metadata": {
        "id": "31c_Z4eL8mou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "body = {\n",
        "    \"knn\": {\n",
        "    \"field\": \"vector\",\n",
        "    \"query_vector\": doc_0_vector,\n",
        "    \"k\": 2,\n",
        "    \"num_candidates\": 10\n",
        "  }\n",
        "}"
      ],
      "metadata": {
        "id": "IdO73PiL8q3U"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knn = {\n",
        "    \"field\": \"vectors\",\n",
        "    \"query_vector\": doc_0_vector,\n",
        "    \"k\": 2,\n",
        "    \"num_candidates\": 10\n",
        "  }"
      ],
      "metadata": {
        "id": "_xI-NOjv9bbP"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = es.search(index='jupyter-vector-demo', knn=knn, size=1)\n"
      ],
      "metadata": {
        "id": "bwQoXata8pZY",
        "outputId": "d6b10d65-aabc-4e75-f165-f63ba890d56f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "error",
          "ename": "BadRequestError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-0bbc6772e5ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'jupyter-vector-demo'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mknn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mknn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/elasticsearch/_sync/client/utils.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    412\u001b[0m                         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m  \u001b[0;31m# type: ignore[return-value]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/elasticsearch/_sync/client/__init__.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, index, aggregations, aggs, allow_no_indices, allow_partial_search_results, analyze_wildcard, analyzer, batched_reduce_size, ccs_minimize_roundtrips, collapse, default_operator, df, docvalue_fields, error_trace, expand_wildcards, explain, ext, fields, filter_path, from_, highlight, human, ignore_throttled, ignore_unavailable, indices_boost, knn, lenient, max_concurrent_shard_requests, min_compatible_shard_node, min_score, pit, post_filter, pre_filter_shard_size, preference, pretty, profile, q, query, request_cache, rescore, rest_total_hits_as_int, routing, runtime_mappings, script_fields, scroll, search_after, search_type, seq_no_primary_term, size, slice, sort, source, source_excludes, source_includes, stats, stored_fields, suggest, suggest_field, suggest_mode, suggest_size, suggest_text, terminate_after, timeout, track_scores, track_total_hits, typed_keys, version)\u001b[0m\n\u001b[1;32m   3797\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m__body\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3798\u001b[0m             \u001b[0m__headers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"content-type\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"application/json\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3799\u001b[0;31m         return self.perform_request(  # type: ignore[return-value]\n\u001b[0m\u001b[1;32m   3800\u001b[0m             \u001b[0;34m\"POST\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m__query\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m__headers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m__body\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3801\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/elasticsearch/_sync/client/_base.py\u001b[0m in \u001b[0;36mperform_request\u001b[0;34m(self, method, path, params, headers, body)\u001b[0m\n\u001b[1;32m    319\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m             raise HTTP_EXCEPTIONS.get(meta.status, ApiError)(\n\u001b[0m\u001b[1;32m    322\u001b[0m                 \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresp_body\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m             )\n",
            "\u001b[0;31mBadRequestError\u001b[0m: BadRequestError(400, 'search_phase_execution_exception', 'failed to create query: to perform knn search on field [vectors], its mapping must have [index] set to [true]')"
          ]
        }
      ]
    }
  ]
}