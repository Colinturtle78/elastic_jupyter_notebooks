{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " Working with Vectors in Elasticsearch",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMt9kCExzcQ7i86Qbo1QWn7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeffvestal/elastic_jupyter_notebooks/blob/main/load_embedding_model_from_hf_to_elastic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading an Sentense Transformer model from Hugging Face into Elastic\n",
        "\n",
        "This code will show you how to set up an ingest pipeline to generate vectors for documents on ingest.\n",
        "\n",
        "Overview of steps\n",
        "1. Set up our python environment\n",
        "2. Setup index mapping\n",
        "3. Configure ingest pipeline\n",
        "4. Index a couple test documents\n",
        "\n",
        "### Requirements\n",
        "This notebook assumes you already have loaded an embedding model into elasticsearch. If you haven't, please start with [this notebook example](https://github.com/jeffvestal/elastic_jupyter_notebooks/blob/main/load_embedding_model_from_hf_to_elastic.ipynb)\n",
        "\n",
        "\n",
        "### Elastic version support\n",
        "Requires Elastic version 8.0+ with a platinum or enterprise license (or trial license)\n",
        "\n",
        "You can set up a [free trial elasticsearch Deployment in Elastic Cloud](https://cloud.elastic.co/registration)."
      ],
      "metadata": {
        "id": "6xoLDtS_6Df1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup\n",
        "This section will set up the python environment with the required libraries"
      ],
      "metadata": {
        "id": "DgxCKQS7mCZw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install and import required python libraries"
      ],
      "metadata": {
        "id": "Ly1f1P-l9ri8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Elastic uses the [eland python library](https://github.com/elastic/eland) to download modesl from Hugging Face hub and load them into elasticsearch"
      ],
      "metadata": {
        "id": "MJAb_8zlPFhQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rUedSzQW9FIF"
      },
      "outputs": [],
      "source": [
        "pip install eland"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install elasticsearch"
      ],
      "metadata": {
        "id": "NK3Wx1I199yB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "id": "cEfiiFXakzdP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install sentence_transformers"
      ],
      "metadata": {
        "id": "I20mDmJboKZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch==1.11"
      ],
      "metadata": {
        "id": "uqcpWrbkBEB9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "from eland.ml.pytorch import PyTorchModel\n",
        "from eland.ml.pytorch.transformers import TransformerModel\n",
        "from elasticsearch import Elasticsearch\n",
        "from elasticsearch.client import MlClient"
      ],
      "metadata": {
        "id": "wyUZXUi4RWWL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configure elasticsearch authentication. \n",
        "The recommended authentication approach is using the [Elastic Cloud ID](https://www.elastic.co/guide/en/cloud/current/ec-cloud-id.html) and a [cluster level API key](https://www.elastic.co/guide/en/kibana/current/api-keys.html)\n",
        "\n",
        "You can use any method you wish to set the required credentials. We are using getpass in this example to prompt for credentials to avoide storing them in github."
      ],
      "metadata": {
        "id": "r7nMIbHke37Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass"
      ],
      "metadata": {
        "id": "Xsd2m7HoTCLm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "es_cloud_id = getpass.getpass('Enter Elastic Cloud ID:  ')\n",
        "es_api_id = getpass.getpass('Enter cluster API key ID:  ') \n",
        "es_api_key = getpass.getpass('Enter cluster API key:  ')"
      ],
      "metadata": {
        "id": "SSGgYHome69o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect to Elastic Cloud"
      ],
      "metadata": {
        "id": "jL4VDnVp96lf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "es = Elasticsearch(cloud_id=es_cloud_id, \n",
        "                   api_key=(es_api_id, es_api_key)\n",
        "                   )\n",
        "es.info() # should return cluster info"
      ],
      "metadata": {
        "id": "I8mVJkKmetXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Information and Status"
      ],
      "metadata": {
        "id": "4UYSzFp3vHdB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## View information about the model\n",
        "This is not required but will allow us to get the model_id as it is stored in elasticsearch as well as verify the model is running / deployed and ready to use in our ingest pipeline"
      ],
      "metadata": {
        "id": "wQwfozwznK4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m = MlClient.get_trained_models(es, model_id=es_model_id)\n",
        "m.body"
      ],
      "metadata": {
        "id": "b4Wv8EJvpfZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set the model_id for ease of reference later"
      ],
      "metadata": {
        "id": "KbbdWiJetJV0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "es_model_id = <set from model_id value above>"
      ],
      "metadata": {
        "id": "P8xW5_lCtUE2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *If* the model is not started we will need to deploy the model\n",
        "\n",
        "You will only need to run this if the model hasn't been deployed. \n",
        "\n",
        "This will load the model on the ML nodes and start the process(es) making it available for the NLP task\n",
        "\n",
        "uncomment the code below"
      ],
      "metadata": {
        "id": "oMGw3sk-pbaN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#s = MlClient.start_trained_model_deployment(es, model_id=es_model_id)\n",
        "#s.body"
      ],
      "metadata": {
        "id": "w5muJ1rLqvUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Verify the model started without issue"
      ],
      "metadata": {
        "id": "ZytlELrsnn_O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#stats = MlClient.get_trained_models_stats(es, model_id=es_model_id)\n",
        "#stats.body['trained_model_stats'][0]['deployment_stats']['nodes'][0]['routing_state']"
      ],
      "metadata": {
        "id": "ZaQUUWe0Hxwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Elasticsearch index setup\n",
        "Here we will configure an index template with settings and mappings to store our vectors and text data\n",
        "\n",
        "The **important** part here will be setting our vector field to be a `dense_vector` type. This will tell elasticsearch to build the HNSW graph for the vectors so we can then use kNN search later. "
      ],
      "metadata": {
        "id": "KEwsReS8zyOc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the index template\n",
        "We will have the following fields\n",
        "\n",
        "- `vectors` of type `dense_vector`\n",
        "- `title` of type `text`\n",
        "- `summary` of type `text`\n",
        "\n",
        "This will match new indices with the name matching the pattern of `jupyter-vector-demo*`"
      ],
      "metadata": {
        "id": "KQvNTOJQ2Jk1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template = {\n",
        "    \"template\": \"jupyter-vector-demo*\",\n",
        "    \"settings\": {\n",
        "        \"number_of_shards\": 1,\n",
        "        \"number_of_replicas\": 1\n",
        "    },\n",
        "    \"mappings\": {\n",
        "        \"properties\": {\n",
        "            \"vectors\": {\n",
        "                \"type\": \"dense_vector\",\n",
        "                \"dims\": 512\n",
        "            },\n",
        "            \"title\": {\n",
        "                \"type\": \"text\"\n",
        "            },\n",
        "            \"summary\": {\n",
        "                \"type\": \"text\"\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "jKUmyAmX0iDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Apply the template\n",
        "Here we apply the templat and give it a name of `jupyter-vector-demo`. This is just the name of the template if we need to modify it later on."
      ],
      "metadata": {
        "id": "vryddQGB3U6q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "es.indices.put_template(name=\"jupyter-vector-demo-template\", body=template)"
      ],
      "metadata": {
        "id": "LEmOQ4IT3XK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "# Working with Vectors\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "8M-4Fc-zn7D_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up the index in elasticsearch to store vectors\n",
        "\n"
      ],
      "metadata": {
        "id": "qpm3jgJOzlxi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate Vector for Query\n",
        "\n",
        "Before we can run a kNN query, we need to convert our query string to a vector."
      ],
      "metadata": {
        "id": "6Hu2n4bmGYkG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a sample query sentence"
      ],
      "metadata": {
        "id": "XXAQXIS0pvfR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "docs =  [\n",
        "    {\n",
        "      \"text_field\": \"Last week I upgraded my iOS version and ever since then my phone has been overheating whenever I use your app.\"\n",
        "    }\n",
        "  ]"
      ],
      "metadata": {
        "id": "wBNV7q5Dwlz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We call the `_infer` endpoint supplying the model_id and the doc[s] we want to vectorize. "
      ],
      "metadata": {
        "id": "T5_BYcpvrLsb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z = MlClient.infer_trained_model(es, model_id=es_model_id, docs=docs, )"
      ],
      "metadata": {
        "id": "ZsWg7XPSGbiu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The vector for the first doc can be accessed in the response dict as shown below"
      ],
      "metadata": {
        "id": "CdC3PkTyrZEV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc_0_vector = z['inference_results'][0]['predicted_value']\n",
        "doc_0_vector"
      ],
      "metadata": {
        "id": "Rle3J5mJXbdf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}