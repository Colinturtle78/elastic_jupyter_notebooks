{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " Elastic - NLP - Load HuggingFace Model with Zero Shot Example",
      "provenance": [],
      "authorship_tag": "ABX9TyNiJerpd68MKKF6aAdA8B3l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f62e1e84e6a040ed8a9cdd7de746ffb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6dc74374e9f54be99be1c2a6b24fb46b",
              "IPY_MODEL_7ca8aaad7a65448faef016d60fd6128b",
              "IPY_MODEL_a14eba165c61474aa5c72e1e49400237"
            ],
            "layout": "IPY_MODEL_7fd5cdcc954640af90658a809b127721"
          }
        },
        "6dc74374e9f54be99be1c2a6b24fb46b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c167ac3f6c54494b01b364c6aa81f33",
            "placeholder": "​",
            "style": "IPY_MODEL_440e5372957e4b66be81a0fea77878e9",
            "value": "100%"
          }
        },
        "7ca8aaad7a65448faef016d60fd6128b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b870328533a04e4a8f0b0ac9b64ac395",
            "max": 32,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ce71cccd6f3d4ffd82f0ad592ec5afb9",
            "value": 32
          }
        },
        "a14eba165c61474aa5c72e1e49400237": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60345525309a4623b7d9267c7a1747ba",
            "placeholder": "​",
            "style": "IPY_MODEL_daf2cd8b9cf84cd2b29f978723d42d1a",
            "value": " 32/32 [00:33&lt;00:00,  1.07 parts/s]"
          }
        },
        "7fd5cdcc954640af90658a809b127721": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c167ac3f6c54494b01b364c6aa81f33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "440e5372957e4b66be81a0fea77878e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b870328533a04e4a8f0b0ac9b64ac395": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce71cccd6f3d4ffd82f0ad592ec5afb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "60345525309a4623b7d9267c7a1747ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "daf2cd8b9cf84cd2b29f978723d42d1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeffvestal/elastic_jupyter_notebooks/blob/main/load_embedding_model_from_hf_to_elastic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading an NLP Embedding model from Hugging Face into Elastic\n",
        "\n",
        "This code will show you how to load a supported embedding model from Hugging Face into an elasticsearch cluster in [Elastic Cloud](https://cloud.elastic.co/)\n",
        "\n",
        "### Elastic version support\n",
        "Requires Elastic version 8.0+ with a platinum or enterprise license (or trial license)\n",
        "\n",
        "You can set up a [free trial elasticsearch Deployment in Elastic Cloud](https://cloud.elastic.co/registration).\n",
        "\n",
        "## Deleteme below\n",
        "\n",
        "Example here is loading a [Zero Shot model](https://huggingface.co/typeform/distilbert-base-uncased-mnli)\n",
        "\n",
        "[Elastic NLP Model Support Docs](https://www.elastic.co/guide/en/machine-learning/current/ml-nlp-model-ref.html) \n",
        "\n",
        "\n",
        "Disclaimer: presented as is with no guarantee."
      ],
      "metadata": {
        "id": "6xoLDtS_6Df1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install and import required python libraries"
      ],
      "metadata": {
        "id": "Ly1f1P-l9ri8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Elastic uses the [eland python library](https://github.com/elastic/eland) to download modesl from Hugging Face hub and load them into elasticsearch"
      ],
      "metadata": {
        "id": "MJAb_8zlPFhQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rUedSzQW9FIF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28fafc37-2d3f-46e4-c323-b7230073a964"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting eland\n",
            "  Downloading eland-8.3.0-py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.7/143.7 KB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting elasticsearch<9,>=8.3\n",
            "  Downloading elasticsearch-8.6.1-py3-none-any.whl (385 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.4/385.4 KB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib<4 in /usr/local/lib/python3.8/dist-packages (from eland) (3.2.2)\n",
            "Requirement already satisfied: pandas<2,>=1.2 in /usr/local/lib/python3.8/dist-packages (from eland) (1.3.5)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.8/dist-packages (from eland) (1.21.6)\n",
            "Collecting elastic-transport<9,>=8\n",
            "  Downloading elastic_transport-8.4.0-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 KB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4->eland) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4->eland) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4->eland) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4->eland) (3.0.9)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas<2,>=1.2->eland) (2022.7.1)\n",
            "Collecting urllib3<2,>=1.26.2\n",
            "  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from elastic-transport<9,>=8->elasticsearch<9,>=8.3->eland) (2022.12.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib<4->eland) (1.15.0)\n",
            "Installing collected packages: urllib3, elastic-transport, elasticsearch, eland\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed eland-8.3.0 elastic-transport-8.4.0 elasticsearch-8.6.1 urllib3-1.26.14\n"
          ]
        }
      ],
      "source": [
        "pip install eland"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install elasticsearch"
      ],
      "metadata": {
        "id": "NK3Wx1I199yB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96f1459d-31de-4417-ebb1-905108026d10"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: elasticsearch in /usr/local/lib/python3.8/dist-packages (8.6.1)\n",
            "Requirement already satisfied: elastic-transport<9,>=8 in /usr/local/lib/python3.8/dist-packages (from elasticsearch) (8.4.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from elastic-transport<9,>=8->elasticsearch) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<2,>=1.26.2 in /usr/local/lib/python3.8/dist-packages (from elastic-transport<9,>=8->elasticsearch) (1.26.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "id": "cEfiiFXakzdP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e32312ff-0ae2-4777-d674-21eaef391c04"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.26.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m71.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.12.0-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m105.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.26.14)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.12.0 tokenizers-0.13.2 transformers-4.26.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install sentence_transformers"
      ],
      "metadata": {
        "id": "I20mDmJboKZw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7652e5c1-3296-4703-c3c1-c232be90522e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentence_transformers\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 KB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.8/dist-packages (from sentence_transformers) (4.26.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from sentence_transformers) (4.64.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from sentence_transformers) (1.13.1+cu116)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (from sentence_transformers) (0.14.1+cu116)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from sentence_transformers) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from sentence_transformers) (1.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from sentence_transformers) (1.7.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (from sentence_transformers) (3.7)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from sentence_transformers) (0.12.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.25.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.4.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (23.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.13.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2022.6.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk->sentence_transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk->sentence_transformers) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->sentence_transformers) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision->sentence_transformers) (7.1.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (1.26.14)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (4.0.0)\n",
            "Building wheels for collected packages: sentence_transformers\n",
            "  Building wheel for sentence_transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence_transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125938 sha256=c8ee7abe71bd203971a09c508a080912c39f61b2f2e80e47ff67f2d0de465229\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/6f/8c/d88aec621f3f542d26fac0342bef5e693335d125f4e54aeffe\n",
            "Successfully built sentence_transformers\n",
            "Installing collected packages: sentencepiece, sentence_transformers\n",
            "Successfully installed sentence_transformers-2.2.2 sentencepiece-0.1.97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch==1.11"
      ],
      "metadata": {
        "id": "uqcpWrbkBEB9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "from eland.ml.pytorch import PyTorchModel\n",
        "from eland.ml.pytorch.transformers import TransformerModel\n",
        "from elasticsearch import Elasticsearch\n",
        "from elasticsearch.client import MlClient"
      ],
      "metadata": {
        "id": "wyUZXUi4RWWL"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from elasticsearch.client import MlClient\n"
      ],
      "metadata": {
        "id": "-dqhRCBUe1U-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "800f35f9-cfc0-41e7-f166-9c88ee62cab3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-8ee2a6f3019e>:1: DeprecationWarning: Importing from the 'elasticsearch.client' module is deprecated. Instead use 'elasticsearch' module for importing the client.\n",
            "  from elasticsearch.client import MlClient\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configure elasticsearch authentication. \n",
        "For this example we are using the [Elastic Cloud ID](https://www.elastic.co/guide/en/cloud/current/ec-cloud-id.html) and a [cluster API key](https://www.elastic.co/guide/en/kibana/current/api-keys.html)\n",
        "\n",
        "You can use any method you wish to set the required credentials. We are using getpass in this example to prompt for credentials."
      ],
      "metadata": {
        "id": "r7nMIbHke37Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass"
      ],
      "metadata": {
        "id": "Xsd2m7HoTCLm"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "es_cloud_id = getpass.getpass('Enter Elastic Cloud ID:  ')\n",
        "es_api_id = getpass.getpass('Enter cluster API key ID:  ') \n",
        "es_api_key = getpass.getpass('Enter cluster API key:  ')"
      ],
      "metadata": {
        "id": "SSGgYHome69o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f2c3702-29a0-476d-b7ae-de28a95223b2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter Elastic Cloud ID:  ··········\n",
            "Enter cluster API key ID:  ··········\n",
            "Enter cluster API key:  ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Connect to Elastic and Load a Hugging Face Model"
      ],
      "metadata": {
        "id": "jL4VDnVp96lf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "es = Elasticsearch(cloud_id=es_cloud_id, \n",
        "                   api_key=(es_api_id, es_api_key)\n",
        "                   )\n",
        "es.info() # should return cluster info"
      ],
      "metadata": {
        "id": "I8mVJkKmetXo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae466297-58f0-4f7a-a080-4e9721e5e9c1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ObjectApiResponse({'name': 'instance-0000000001', 'cluster_name': 'a7bf48bf42ad403ab45dd6b90b860f85', 'cluster_uuid': 'gEbjuhUOSyCVzG4Gz2SQ2w', 'version': {'number': '8.6.0', 'build_flavor': 'default', 'build_type': 'docker', 'build_hash': 'f67ef2df40237445caa70e2fef79471cc608d70d', 'build_date': '2023-01-04T09:35:21.782467981Z', 'build_snapshot': False, 'lucene_version': '9.4.2', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'})"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Supported `task_type` values](https://github.com/elastic/eland/blob/15a300728876022b206161d71055c67b500a0192/eland/ml/pytorch/transformers.py#*L41*)"
      ],
      "metadata": {
        "id": "QmZ1fkwYM5er"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download an embedding model from Hugging Face using the HF copy link\n",
        "\n",
        "[sentence-transformers/msmarco-MiniLM-L-12-v3](https://huggingface.co/sentence-transformers/msmarco-MiniLM-L-12-v3)\n"
      ],
      "metadata": {
        "id": "10VvWJ87alld"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hf_model_id='sentence-transformers/msmarco-MiniLM-L-12-v3'\n",
        "tm = TransformerModel(hf_model_id, \"text_embedding\")"
      ],
      "metadata": {
        "id": "zPV3oFsKiYFL"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "es_model_id = tm.elasticsearch_model_id()\n",
        "es_model_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "XkIQBBCbdqvQ",
        "outputId": "90593680-209a-43ba-efa5-a7e062f6462f"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'sentence-transformers__msmarco-minilm-l-12-v3'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Export the model in a TorchScrpt representation which Elasticsearch uses"
      ],
      "metadata": {
        "id": "p0L2cfYwbIld"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tmp_path = \"models\"\n",
        "Path(tmp_path).mkdir(parents=True, exist_ok=True)\n",
        "model_path, config, vocab_path = tm.save(tmp_path)"
      ],
      "metadata": {
        "id": "GsSpvvP-nbCK"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import model into Elasticsearch\n",
        "Model should not already exist in elasticsearch"
      ],
      "metadata": {
        "id": "k1a_yNo6ba2E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ptm = PyTorchModel(es, es_model_id)\n",
        "ptm.import_model(model_path=model_path, config_path=None, vocab_path=vocab_path, config=config) "
      ],
      "metadata": {
        "id": "Z4QD71Apnj4j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "f62e1e84e6a040ed8a9cdd7de746ffb3",
            "6dc74374e9f54be99be1c2a6b24fb46b",
            "7ca8aaad7a65448faef016d60fd6128b",
            "a14eba165c61474aa5c72e1e49400237",
            "7fd5cdcc954640af90658a809b127721",
            "8c167ac3f6c54494b01b364c6aa81f33",
            "440e5372957e4b66be81a0fea77878e9",
            "b870328533a04e4a8f0b0ac9b64ac395",
            "ce71cccd6f3d4ffd82f0ad592ec5afb9",
            "60345525309a4623b7d9267c7a1747ba",
            "daf2cd8b9cf84cd2b29f978723d42d1a"
          ]
        },
        "outputId": "a09239ec-b38b-4bc2-b033-538ca90c8b12"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/32 [00:00<?, ? parts/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f62e1e84e6a040ed8a9cdd7de746ffb3"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Operationalizing the Model"
      ],
      "metadata": {
        "id": "4UYSzFp3vHdB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deploy the model\n",
        "This will load the model on the ML nodes for use"
      ],
      "metadata": {
        "id": "oMGw3sk-pbaN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List the in elasticsearch\n",
        "m = MlClient.get_trained_models(es, model_id=es_model_id)\n",
        "m.body"
      ],
      "metadata": {
        "id": "b4Wv8EJvpfZI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96af9b56-1e97-4720-f7c4-d98c1045ce56"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'count': 1,\n",
              " 'trained_model_configs': [{'model_id': 'sentence-transformers__msmarco-minilm-l-12-v3',\n",
              "   'model_type': 'pytorch',\n",
              "   'created_by': 'api_user',\n",
              "   'version': '8.6.0',\n",
              "   'create_time': 1675720672194,\n",
              "   'model_size_bytes': 0,\n",
              "   'estimated_operations': 0,\n",
              "   'license_level': 'platinum',\n",
              "   'description': \"Model sentence-transformers/msmarco-MiniLM-L-12-v3 for task type 'text_embedding'\",\n",
              "   'tags': [],\n",
              "   'input': {'field_names': ['text_field']},\n",
              "   'inference_config': {'text_embedding': {'vocabulary': {'index': '.ml-inference-native-000001'},\n",
              "     'tokenization': {'bert': {'do_lower_case': True,\n",
              "       'with_special_tokens': True,\n",
              "       'max_sequence_length': 512,\n",
              "       'truncate': 'first',\n",
              "       'span': -1}}}},\n",
              "   'location': {'index': {'name': '.ml-inference-native-000001'}}}]}"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# start trained model deployment\n",
        "s = MlClient.start_trained_model_deployment(es, model_id=es_model_id)\n",
        "s.body\n",
        "\n",
        "# You can see model state in Kibana -> Machine Learning -> Model Management -> Trained Models"
      ],
      "metadata": {
        "id": "w5muJ1rLqvUW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9be1bf60-d537-4136-f905-25de4d7ea9fe"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:elastic_transport.node_pool:Node <Urllib3HttpNode(https://a7bf48bf42ad403ab45dd6b90b860f85.us-central1.gcp.cloud.es.io:443)> has been marked alive after a successful request\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'assignment': {'task_parameters': {'model_id': 'sentence-transformers__msmarco-minilm-l-12-v3',\n",
              "   'model_bytes': 132922074,\n",
              "   'threads_per_allocation': 1,\n",
              "   'number_of_allocations': 1,\n",
              "   'queue_capacity': 1024,\n",
              "   'cache_size': '132922074b',\n",
              "   'priority': 'normal'},\n",
              "  'routing_table': {'dDqmmPySSKuH8d7HcF54uA': {'current_allocations': 1,\n",
              "    'target_allocations': 1,\n",
              "    'routing_state': 'started',\n",
              "    'reason': ''}},\n",
              "  'assignment_state': 'started',\n",
              "  'start_time': '2023-02-06T23:39:10.493431663Z',\n",
              "  'max_assigned_allocations': 1}}"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stats = MlClient.get_trained_models_stats(es, model_id=es_model_id)\n",
        "stats.body['trained_model_stats'][0]['deployment_stats']['nodes'][0]['routing_state']"
      ],
      "metadata": {
        "id": "ZaQUUWe0Hxwz",
        "outputId": "40f007b9-a0dc-4430-bd37-bb4b4f22665b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'routing_state': 'failed',\n",
              " 'reason': 'inference process crashed due to reason [[sentence-transformers__msmarco-minilm-l-12-v3] pytorch_inference/39784 process stopped unexpectedly: Error loading the model: version_ <= kMaxSupportedFileFormatVersionINTERNAL ASSERT FAILED at \"/usr/src/pytorch/caffe2/serialize/inline_container.cc\":140, please report a bug to PyTorch. Attempted to read a PyTorch file with version 10, but the maximum supported version for reading is 9. Your PyTorch installation may be too old.\\n]'}"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate Vector for Query\n"
      ],
      "metadata": {
        "id": "6Hu2n4bmGYkG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#{\n",
        "#  \"docs\": [{\"text_field\": \"What was Jean Valjean prisoner number?\"}]\n",
        "#}\n",
        "\n",
        "docs =  [\n",
        "    {\n",
        "      \"text_field\": \"Last week I upgraded my iOS version and ever since then my phone has been overheating whenever I use your app.\"\n",
        "    }\n",
        "  ]"
      ],
      "metadata": {
        "id": "wBNV7q5Dwlz6"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# future reference do not use yet\n",
        "#z = MlClient.infer_trained_model_deployment(es, model_id =es_model_id, docs=docs, )\n",
        "z = MlClient.infer_trained_model(es, model_id=es_model_id, docs=docs, )"
      ],
      "metadata": {
        "id": "ZsWg7XPSGbiu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "9bcfc423-72bb-493b-cc15-05bd9f16b8c0"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:elastic_transport.node_pool:Node <Urllib3HttpNode(https://a7bf48bf42ad403ab45dd6b90b860f85.us-central1.gcp.cloud.es.io:443)> has failed for 1 times in a row, putting on 1 second timeout\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ConflictError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mConflictError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-00b02264009b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# future reference do not use yet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#z = MlClient.infer_trained_model_deployment(es, model_id =es_model_id, docs=docs, )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMlClient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_trained_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_id\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mes_model_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/elasticsearch/_sync/client/utils.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    412\u001b[0m                         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m  \u001b[0;31m# type: ignore[return-value]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/elasticsearch/_sync/client/ml.py\u001b[0m in \u001b[0;36minfer_trained_model\u001b[0;34m(self, model_id, docs, error_trace, filter_path, human, inference_config, pretty, timeout)\u001b[0m\n\u001b[1;32m   2279\u001b[0m             \u001b[0m__query\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"timeout\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2280\u001b[0m         \u001b[0m__headers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"accept\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"application/json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"content-type\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"application/json\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2281\u001b[0;31m         return self.perform_request(  # type: ignore[return-value]\n\u001b[0m\u001b[1;32m   2282\u001b[0m             \u001b[0;34m\"POST\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m__query\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m__headers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m__body\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2283\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/elasticsearch/_sync/client/_base.py\u001b[0m in \u001b[0;36mperform_request\u001b[0;34m(self, method, path, params, headers, body)\u001b[0m\n\u001b[1;32m    319\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m             raise HTTP_EXCEPTIONS.get(meta.status, ApiError)(\n\u001b[0m\u001b[1;32m    322\u001b[0m                 \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresp_body\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m             )\n",
            "\u001b[0;31mConflictError\u001b[0m: ConflictError(409, 'status_exception', 'Trained model [sentence-transformers__msmarco-minilm-l-12-v3] is not allocated to any nodes')"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using requests until MlClient.infer_trained_model_deployment is updated to accept inference extra configs\n",
        "import requests\n",
        "from requests.auth import HTTPBasicAuth\n",
        "import urllib.parse\n",
        "\n",
        "endpoint = '_ml/trained_models/%s/deployment/_infer' % model_id\n",
        "url = urllib.parse.urljoin(es_url, endpoint)\n",
        "\n",
        "body = {\n",
        "  \"docs\": [\n",
        "    {\n",
        "      \"text_field\": \"Last week I upgraded my iOS version and ever since then my phone has been overheating whenever I use your app.\"\n",
        "    }\n",
        "  ],\n",
        "  \"inference_config\": {\n",
        "    \"zero_shot_classification\": {\n",
        "      \"labels\": [\n",
        "        \"mobile\",\n",
        "        \"website\",\n",
        "        \"billing\",\n",
        "        \"account access\"\n",
        "      ],\n",
        "      \"multi_label\": True\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "resp = requests.post(url, auth=HTTPBasicAuth(es_user, es_pass), json=body)\n",
        "r = resp.json()\n",
        "print('Predicted value is: %s with a probability of %0.2f%%' % (r['predicted_value'], r['prediction_probability'] * 100))\n",
        "print('=-=-=-=')\n",
        "print('Full Probability output:')\n",
        "for c in r['top_classes']:\n",
        "    print ('%s probability of %0.5f%%' % (c['class_name'], c['class_probability'] * 100))"
      ],
      "metadata": {
        "id": "tf9c-XkrQTM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Just to see the full doc\n",
        "resp.json()"
      ],
      "metadata": {
        "id": "f3JRG4SeaESo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}